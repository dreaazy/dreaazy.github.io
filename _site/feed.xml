<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-10-03T19:04:26+02:00</updated><id>http://localhost:4000/feed.xml</id><subtitle>This is my data blog! I can add a description here.</subtitle><author><name>Simone Piccinini</name><email>piccinini.simone2005@gmail.com</email></author><entry><title type="html">PageRank</title><link href="http://localhost:4000/blog/2025/10/03/PageRank.html" rel="alternate" type="text/html" title="PageRank" /><published>2025-10-03T00:00:00+02:00</published><updated>2025-10-03T00:00:00+02:00</updated><id>http://localhost:4000/blog/2025/10/03/PageRank</id><content type="html" xml:base="http://localhost:4000/blog/2025/10/03/PageRank.html">&lt;p&gt;The pipeline for training a Graph Neural Network can be schematized as follows:
&lt;strong&gt;Input graph → Structural features → Learning algorithm → Prediction&lt;/strong&gt;
One of the most challenging aspects of this pipeline is the design of structural features. These features aim to capture the essential patterns and relationships within the graph. Automating this process is a key goal in graph machine learning, and it is commonly referred to as &lt;strong&gt;feature engineering&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;These are few of the possible node level features:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;node degree (treats all neighbours equally)&lt;/li&gt;
  &lt;li&gt;node centrality&lt;/li&gt;
  &lt;li&gt;clustering coefficient&lt;/li&gt;
  &lt;li&gt;graphlets&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Different ways to enstablish these features from a graph are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;engienvector centrality&lt;/li&gt;
  &lt;li&gt;betweenness centrality&lt;/li&gt;
  &lt;li&gt;closeness centrality (how close to the network)&lt;/li&gt;
  &lt;li&gt;and many others&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;engienvector-centrality&quot;&gt;Engienvector centrality&lt;/h3&gt;

&lt;p&gt;A node $\large v$ is important if surrounded by important neighboring nodes&lt;/p&gt;

\[\large
c_v=\frac{1}{\lambda}\sum_{u \in N(v)} c_u\]

&lt;p&gt;$\lambda$ is a positive constant, it is used to normalize.
The basic notion of this feature engineering task is “The more important my friends the more important I am”.&lt;/p&gt;

&lt;p&gt;The last equation can be expressed in a matrix form:&lt;/p&gt;

\[\large
\lambda \cdot c= A \cdot c \quad (1)\]

&lt;p&gt;This is an eigenvector/eigenvalue equation.&lt;/p&gt;

&lt;p&gt;As we will see later, if the graph is &lt;strong&gt;undirected and connected&lt;/strong&gt;, by &lt;strong&gt;Perron-Frobenius Theorem&lt;/strong&gt; the largest eigenvalue is &lt;strong&gt;always positive and unique&lt;/strong&gt;, and the corresponding eigenvector is strictly positive.&lt;/p&gt;

&lt;p&gt;The leading eigenvector $\large c_{max}$ is used as a centrality score.&lt;/p&gt;

&lt;p&gt;It’s not about how many nodes are connected with you, but how important are the nodes that are connected with you.&lt;/p&gt;

&lt;p&gt;Eigenvector centrality measures a node’s importance based on of its neighbors, assigning higher scores to nodes connected to other influential nodes. PageRank extends this idea by introducing a &lt;strong&gt;damping factor&lt;/strong&gt;, which simulates random jumps across the network. This adjustment makes PageRank more robust to &lt;strong&gt;dangling nodes&lt;/strong&gt; (nodes with no outgoing links) and &lt;strong&gt;spider traps&lt;/strong&gt; (subgraphs that can trap random walks), which can distort standard eigenvector centrality. By computing PageRank, one effectively obtains a &lt;strong&gt;principal eigenvector of the Google matrix&lt;/strong&gt;, and the resulting scores can be used as features that capture both the &lt;strong&gt;structural connectivity&lt;/strong&gt; and &lt;strong&gt;influence propagation&lt;/strong&gt; in the network. Compared to pure eigenvector centrality, PageRank provides more stable and meaningful importance values, making it a better choice for feature extraction in graph-based learning tasks.&lt;/p&gt;

&lt;h3 id=&quot;the-web-is-a-directed-graph&quot;&gt;The web is a directed graph&lt;/h3&gt;

&lt;p&gt;Link analysis algorithms:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Pagerank&lt;/li&gt;
  &lt;li&gt;Personalized page rank&lt;/li&gt;
  &lt;li&gt;Random walk with restarst&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The PageRank idea:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;All in-links are not equal: some are more important than others&lt;/li&gt;
  &lt;li&gt;Recursive nature, the importance of a node is carried by the importance of other nodes.&lt;/li&gt;
  &lt;li&gt;A “vote” from an important page is worth more:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If a page $\large i$ with importance $\large r_i$ has $\large d_i$ out-links, each link gets $\Large \frac{r_i}{d_i}$ votes.
Page $\large j$’s own importance $\large r_j$ is the sum of the votes n its in-links.&lt;/p&gt;

&lt;p&gt;So we can define &lt;strong&gt;“rank”&lt;/strong&gt; $\large r_j$ for a node $\large j$ to be:
\(\large
r_j = \sum_{i \to j} \frac{r_i}{d_i} \quad (2)\)
$d_i$ … out degree of node $\large i$.&lt;/p&gt;

&lt;p&gt;It’s possible to solve this as a system using gaussian elimination, but it’s not scalable.&lt;/p&gt;

&lt;p&gt;We can represent the last equation using the matrix form, we have to introduce the &lt;strong&gt;Markov matrix&lt;/strong&gt; or also called &lt;strong&gt;stochastic adjacency matrix&lt;/strong&gt;.
More theory about the Markov stochastic matrix later.&lt;/p&gt;

&lt;p&gt;Let page $\large j$ have $\large d_j$ out-links.
If $\large j \to i$, then $\large M_{ij} = 1/d_j$.&lt;/p&gt;

&lt;p&gt;$\large M$ is a &lt;strong&gt;column stochastic matrix&lt;/strong&gt;, this means that every column sums to 1.
Now we can write the equation &lt;strong&gt;(2)&lt;/strong&gt; in matrix form as:&lt;/p&gt;

\[\large
r = M \cdot r \quad(3)\]

&lt;p&gt;Solving systems of linear equations is a frequent necessity for Web search applications, but the magnitude of computations is usually too large for direct solution methods based on Gaussian elimination to be effective. Consequently, iterative techniques are often the only choice, and, because of size, sparsity, and memory considerations, the preferred algorithms are the simpler methods based on &lt;strong&gt;matrix-vector products&lt;/strong&gt; that require no additional storage beyond that of the original data. Linear stationary iterative methods are the most common.&lt;/p&gt;

&lt;p&gt;Appreciate the similarity between this equation and the &lt;strong&gt;(1)&lt;/strong&gt; equation, the only difference is that $\large A$ is the adjacency matrix, while $\large M$ is the &lt;strong&gt;Markov matrix&lt;/strong&gt; or &lt;strong&gt;stochastic matrix&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;connection-to-random-walk&quot;&gt;Connection to random walk:&lt;/h3&gt;

&lt;p&gt;Imagine a random surfer that at some time $\large t$ is on some page $\large i$.
at time $\large t+1$ te surfer follow an out-link from $\large i$ uniformly at random.&lt;/p&gt;

&lt;p&gt;Eventually it ends up in a page $\large j$ linked from $\large i$.&lt;/p&gt;

&lt;p&gt;let $\large p(t)$ be the vector whose $\large i^{th}$ coordinates is the probability that the surfer is at page $\large i$ at time $\large t$.
So $\large p(t)$ is a probability distribution over pages.&lt;/p&gt;

&lt;p&gt;To compute where the surfer will be at the time $\large t+1$ we can apply it to the left the &lt;strong&gt;column stochastic matrix&lt;/strong&gt;.&lt;/p&gt;

\[\large 

p(t+1) = M \cdot p(t) \quad (4)\]

&lt;p&gt;The entry $\large p_j(t+1)$ gives the probability that the surfer is on node $\large j$ at time $\large t+1$. It is computed by summing the contributions from all nodes that link to $\large j$. 
Formally:&lt;/p&gt;

\[\large
p_j(t+1) = \sum_{i \to j} M_{ij} \, p_i(t)\]

&lt;p&gt;&lt;strong&gt;Suppose&lt;/strong&gt; the random walk reaches a state where:&lt;/p&gt;

\[\large
p(t+1) = M \cdot p(t) = p(t)\]

&lt;p&gt;Then $\large p(t)$ is stationary distribution of random walk.
Our original rank vector $\large r$ satisfies $\large r = M \cdot r$, that means that our vector $\large r$ is a stationary distribution for the random walk!&lt;/p&gt;

&lt;p&gt;How do we solve the equation:&lt;/p&gt;

\[\large 1\cdot r = M r\]

&lt;p&gt;Starting from any vector $ u$, the limit $ M(M(… M(Mu)))$ is the long-term distribution of the surfers.
When applying a linear map $ u \to Mu$ again and again, we obtain a discrete dynamical system. We want to understand what happens with the orbit $ u_{1} = M u, u_{2} = MMu , u_{3}=MMMu$, … and find a closed formula for $ M^n u$.&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;p&gt;The one-dimensional discrete dynamical system $ x \to ax$  or $ x_{n+1} = ax_n$ has the solution $ x_n = a^nx_{0}$. The value $ 1.0320 · 1000 = 1806.11$ for example is the balance on a bank account which had $ 1000$ dollars 20 years ago if the interest rate was a constant $3$ percent.&lt;/p&gt;

&lt;p&gt;If $ u$ is an eigenvector with eigenvalue $\lambda$, then $ Mu = λu, M^2u = M(Mu)) = Mλu = λMu = λ^2u$ and more generally $ M^n u = λ^n u$.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[!note] Statement
The PageRank is the principal eigenvector of M.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If $ r$ is the limit of the product $ MM \dots Mu$, then $ r$ satisfies the flow equation $ 1 \cdot r = M\cdot r$
So $ r$ is the principal eigenvector of $ M$ with eigenvalue 1.&lt;/p&gt;

&lt;p&gt;To efficiently solve for we can use the &lt;strong&gt;Power iteration method.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Summary&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;PageRank measures importance of nodes in a graph using the link structure of the web&lt;/li&gt;
  &lt;li&gt;Yo can simulate a random web surfer using stochastic adjacency matrix M&lt;/li&gt;
  &lt;li&gt;PageRank solves $\large r = M \cdot r$ where $\large r$ can be viewed as both the principle eigenvector of $\large M$ and as the stationary distribution of a random walk over the graph.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;important-questions&quot;&gt;Important questions&lt;/h4&gt;

&lt;p&gt;At this point we have an intuitive knowledge of how this algorithm works, but to properly understand the essence of it, it’s necessary to dive into the mathematics that lies behind the algorithm.
We ought to ask ourself these important questions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Will this iterative process continue indefinitely or will it converge?&lt;/li&gt;
  &lt;li&gt;Under what circumstances or properties of H is it guaranteed to converge?&lt;/li&gt;
  &lt;li&gt;Will it converge to something that makes sense in the context of the PageRank problem?&lt;/li&gt;
  &lt;li&gt;Will it converge to just one vector or multiple vectors?&lt;/li&gt;
  &lt;li&gt;Does the convergence depend on the starting vector π(0)T ?&lt;/li&gt;
  &lt;li&gt;If it will converge eventually, how long is “eventually”? That is, how many iterations can we expect until convergence?
In the following part of the article, I’m going to answer this questions and provide and example of this algorithm give an instance.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;power-iteration&quot;&gt;&lt;strong&gt;Power iteration&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Iterative procedure that will update over time our rank vector $\large r$.
We start initiating every node with an initial state, continue the process until the states stabilizes.&lt;/p&gt;

&lt;p&gt;Repeat until convergence: 
\(\large
r_j^{t+1}=\sum_{i \to j} \frac{r_j^t}{d_i}\)&lt;/p&gt;

&lt;p&gt;Initialize $\large r^0 = [\frac{1}{N}, \dots, \frac{1}{N}]^T$
Iterate: $\large r^{t+1} = M r^t$ that is the same of $\large r_j^{t+1}=\sum_{i \to j} \frac{r_j^t}{d_i}$
Stop when $\large |r^{t+1}-r^t| &amp;lt; \epsilon$&lt;/p&gt;

&lt;p&gt;About 50 iterations is sufficient to estimate the limiting solution.&lt;/p&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;markov-matrix&quot;&gt;Markov matrix&lt;/h3&gt;

&lt;p&gt;A discrete-time Markov chain is a sequence of random variables 
$X_1, X_2, X_3, \ldots$ 
with the Markov property, namely that the probability of moving to the next state depends &lt;strong&gt;only on the present state&lt;/strong&gt; and not on the previous states:&lt;/p&gt;

\[\large
\Pr\!\left( X_{n+1} = x \;\middle|\; X_1 = x_1, X_2 = x_2, \ldots, X_n = x_n \right)
=
\Pr\!\left( X_{n+1} = x \;\middle|\; X_n = x_n \right),\]

&lt;p&gt;If both conditional probabilities are well defined, that is, if&lt;/p&gt;

\[\large
\Pr\!\left( X_1 = x_1, \ldots, X_n = x_n \right) &amp;gt; 0.\]

&lt;p&gt;The possible values of $X_i$ form a countable set $S$ called the state space of the chain.&lt;/p&gt;

&lt;p&gt;The matrix describing the markov chain is called transition matrix, but it’s also very common to call it &lt;strong&gt;stochastic matrix&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;A stochastic matrix is an $\large n \times n$ matrix where all entries are nonnegative and each row adds up to 1.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/assets/PageRank-media/Markov Matrix.png&quot; class=&quot;wikilink&quot; alt=&quot;./resources/tensor.svg&quot; /&gt;
&lt;figcaption aria-hidden=&quot;true&quot;&gt;markov matrix&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;ROWS&lt;/strong&gt; represent &lt;strong&gt;NOW&lt;/strong&gt;, or &lt;strong&gt;FROM&lt;/strong&gt; $(X_t)$;&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;COLUMNS&lt;/strong&gt; represent NEXT, or TO $(X_t+1)$;&lt;/li&gt;
  &lt;li&gt;Entry $(i, j)$ is the &lt;strong&gt;CONDITIONAL&lt;/strong&gt; probability that $NEXT = j$, given that $NOW = i$: the probability of going &lt;strong&gt;FROM&lt;/strong&gt; state $i$ TO &lt;strong&gt;state&lt;/strong&gt; $j$.&lt;/li&gt;
&lt;/ul&gt;

\[\large
p_{ij} = \mathbb{P}(X_{t+1} = j | X_t=i)\]

&lt;p&gt;A &lt;strong&gt;probability vector&lt;/strong&gt; or &lt;strong&gt;stochastic vector&lt;/strong&gt; is a vector with non-negative entries that add up to one.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[!note] Statement
A &lt;strong&gt;Markov matrix&lt;/strong&gt; $\large A$ always has an eigenvalue $\large 1$. All other eigenvalues are in absolute value smaller or equal to $\large 1$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof:&lt;/h3&gt;

&lt;p&gt;Consider the transpose matrix $A^T$. Since $A$ is row-stochastic, the sum of the 
entries in each row of $A$ is $1$, which means that the sum of the entries in each 
column of $A^T$ is $1$. Thus&lt;/p&gt;

\[A^T 
\begin{bmatrix}
1 \\ 1 \\ \vdots \\ 1
\end{bmatrix} 
=
\begin{bmatrix}
1 \\ 1 \\ \vdots \\ 1
\end{bmatrix},\]

&lt;p&gt;so $A^T$ has eigenvalue $1$ with eigenvector 
$\mathbf{1} = (1,1,\ldots,1)^T$.&lt;br /&gt;
Since $A$ and $A^T$ have the same characteristic polynomial, they share the same 
eigenvalues. Therefore, $A$ also has eigenvalue $1$.&lt;/p&gt;

&lt;p&gt;Now suppose $v$ is an eigenvector of $A$ with eigenvalue $\lambda$ such that 
$|\lambda| &amp;gt; 1$. Then&lt;/p&gt;

\[A^n v = \lambda^n v,\]

&lt;p&gt;which grows in length exponentially as $n \to \infty$. In particular, for large $n$, 
some entry of $A^n v$ must have magnitude larger than $1$.&lt;/p&gt;

&lt;p&gt;However, $A^n$ is also row-stochastic (this can be shown by induction), so all its 
entries are nonnegative and each row sums to $1$. Hence every entry of $A^n$ is 
bounded by $1$, and multiplying $A^n$ by any probability vector produces another 
probability vector. This contradicts the assumption that an eigenvalue with 
$|\lambda| &amp;gt; 1$ exists.&lt;/p&gt;

&lt;p&gt;Therefore, all eigenvalues $\lambda$ of $A$ satisfy $|\lambda| \leq 1$, with $1$ 
&lt;strong&gt;always&lt;/strong&gt; being an eigenvalue.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;perronfrobenius-theory&quot;&gt;Perron–Frobenius Theory&lt;/h3&gt;
&lt;p&gt;In a presentation held by Hans Schneider titled “Why I Love Perron–Frobenius”, he addressed how the Perron-Frobenius theory of nonnegative matrices is not only extremely useful, but it is also among the most beautiful theories in mathematics.&lt;/p&gt;

&lt;p&gt;The applications involving PageRank, HITS, and other ranking schemes help to underscore this principle. A matrix A is said to be nonnegative when each entry is a nonnegative number (denote this by writing $\large A ≥ 0$). Similarly, $\large A$ is a positive matrix when each $\large a_{ij}$ &amp;gt; 0 (write $\large A &amp;gt; 0$). For example, the hyperlink matrix H and the stochastic matrix M that are at the foundation of PageRank are &lt;strong&gt;nonnegative matrices&lt;/strong&gt;, and the Google matrix G is a &lt;strong&gt;positive&lt;/strong&gt; matrix. Consequently, properties of positive and nonnegative matrices govern the behavior of PageRank, and the &lt;strong&gt;Perron–Frobenius theory&lt;/strong&gt; reveals these properties by describing the nature of the dominant eigenvalues and eigenvectors of positive and nonnegative matrices.&lt;/p&gt;

&lt;p&gt;For a matrix $A$, the &lt;strong&gt;spectral radius&lt;/strong&gt; is defined as&lt;/p&gt;

\[\rho(A) = \max \{ |\lambda| : \lambda \in \sigma(A) \},\]

&lt;p&gt;that is, the maximum absolute value among the eigenvalues of $A$.&lt;/p&gt;

&lt;p&gt;In Perron’s theorem, we set $r = \rho(A)$, meaning that the eigenvalue under consideration is precisely the one with the largest modulus.&lt;br /&gt;
For positive matrices ($A &amp;gt; 0$), this eigenvalue $r$ is real, positive, simple, and associated with an eigenvector having all positive components.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[!theorem] Perron’s Theorem for Positive Matrices
If $A_{n \times n} &amp;gt; 0$ with $r = \rho(A)$, then the following statements are true:&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;$r &amp;gt; 0$.&lt;/li&gt;
    &lt;li&gt;$r \in \sigma(A)$ (r is called the &lt;em&gt;Perron root&lt;/em&gt;).&lt;/li&gt;
    &lt;li&gt;$\text{alg mult}_A(r) = 1$ (the Perron root is simple).&lt;/li&gt;
    &lt;li&gt;There exists an eigenvector $x &amp;gt; 0$ such that $Ax = rx$.&lt;/li&gt;
    &lt;li&gt;The Perron vector is the unique vector defined by&lt;br /&gt;
\(Ap = rp, \quad p &amp;gt; 0, \quad \|p\|_1 = 1,\)
and, except for positive multiples of $p$, there are no other nonnegative eigenvectors for $A$, regardless of the eigenvalue.&lt;/li&gt;
    &lt;li&gt;$r$ is the only eigenvalue on the spectral circle of $A$.&lt;/li&gt;
    &lt;li&gt;\(r = \max_{x \in N} f(x), \quad \text{(the Collatz–Wielandt formula)},\)
   where&lt;br /&gt;
   \(f(x) = \min_{\substack{1 \leq i \leq n \\ x_i \neq 0}} \frac{[Ax]_i}{x_i}, 
   \quad 
   N = \{ x \mid x \geq 0, \, x \neq 0 \}.\)&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Perron’s theorem for positive matrices is a powerful result, so it’s only natural to ask what happens when zero entries appear. Not all is lost if we are willing to be flexible. The next theorem says that part of Perron’s theorem for positive matrices can be extended to nonnegative matrices by sacrificing the existence of a positive eigenvector for a nonnegative one.&lt;/p&gt;

&lt;h3 id=&quot;perrons-theorem-for-nonnegative-matrices&quot;&gt;Perron’s Theorem for Nonnegative Matrices&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;[!theorem] Perron’s Theorem for Nonnegative Matrices
If $A_{n \times n} \geq 0$ with $r = \rho(A)$, the following statements are true:&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;$r \in \sigma(A)$ (but $r = 0$ is possible).&lt;/li&gt;
    &lt;li&gt;There exists an eigenvector $x \geq 0$ such that $Ax = rx$.&lt;/li&gt;
    &lt;li&gt;The Collatz–Wielandt formula remains valid.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;irreducibility-and-connectivity&quot;&gt;Irreducibility and Connectivity&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;[!note] Statement
A square matrix (A) is &lt;strong&gt;irreducible&lt;/strong&gt; if and only if its directed graph is strongly connected. Equivalently, for each pair of indices $i,j$ there exist $t\ge 1$ and indices $k_1,\dots,k_{t-1}$ such that
\(\Large
a_{i k_1} \, a_{k_1 k_2} \cdots a_{k_{t-1} j} \;&amp;gt;\; 0.\)
Another equivalent characterization is: (A) is irreducible if and only if there does &lt;strong&gt;not&lt;/strong&gt; exist a permutation matrix (P) for which
\(\Large
P^{\top} A P \;=\; \begin{bmatrix} X &amp;amp; Y \\[4pt] 0 &amp;amp; Z \end{bmatrix},\)
Where $X$ and $Z$ are square blocks. In other words, $A$ cannot be put into a nontrivial block upper-triangular form.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;perron-frobenius-theorem&quot;&gt;Perron-Frobenius Theorem&lt;/h3&gt;

&lt;p&gt;Frobenius’s contribution was to realize that while properties 1, 3, 4, and 6 in Perron’s theorem for positive matrices can be lost when zeros creep into the picture (i.e., for nonnegative matrices), the trouble is not simply the existence of zero entries, but rather the problem is the location of the zero entries. In other words, Frobenius realized that the lost properties 1, 3, and 4 are in fact not lost when the zeros are in just the right locations—namely the locations that ensure that the matrix is irreducible. Unfortunately irreducibility alone still does not save property 6— it remains lost.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;[!theorem] Perron–Frobenius Theorem&lt;br /&gt;
Let $\large A \in \mathbb{R}^{n \times n}$ with $\large A \ge 0$ and irreducible. Then:&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;$\large r = \rho(A) &amp;gt; 0$.&lt;/li&gt;
    &lt;li&gt;$\large r \in \sigma(A)$ (that is, $r$ is the Perron root).&lt;/li&gt;
    &lt;li&gt;$\large \operatorname{algmult}_A(r) = 1$ (the Perron root is simple).&lt;/li&gt;
    &lt;li&gt;There exists an eigenvector $\large x &amp;gt; 0$ such that&lt;br /&gt;
\(\large
A x = r x .\)&lt;/li&gt;
    &lt;li&gt;The Perron vector is the unique vector defined by&lt;br /&gt;
\(\large
A p = r p, \quad p &amp;gt; 0, \quad \|p\|_1 = 1 ,\)&lt;br /&gt;
and, except for positive multiples of $\large p$, there are no other nonnegative eigenvectors of $\large A$, regardless of the eigenvalue.&lt;/li&gt;
    &lt;li&gt;$\large r$ need not be the only eigenvalue on the spectral circle of $\large A$.&lt;/li&gt;
    &lt;li&gt;(Collatz–Wielandt formula)&lt;br /&gt;
\(\large
r = \max_{x \in N} f(x),\)&lt;br /&gt;
where&lt;br /&gt;
\(\large
f(x) = \min_{1 \le i \le n, \, x_i \neq 0} \frac{[Ax]_i}{x_i}, 
\quad N = \{ x \mid x \ge 0, \, x \neq 0 \}.\)&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;irreducible-markov-chains&quot;&gt;Irreducible Markov Chains&lt;/h4&gt;

&lt;p&gt;Analyzing limiting properties of Markov chains requires that the class of stochastic matrices (and hence the class of stationary Markov chains) be divided into four mutually exclusive categories.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;M is irreducible&lt;/strong&gt; with $\displaystyle \lim_{k \to \infty} M^k$ existing&lt;br /&gt;
(i.e., M is primitive).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;M is irreducible&lt;/strong&gt; with $\displaystyle \lim_{k \to \infty} M^k$ not existing&lt;br /&gt;
(i.e., M is imprimitive).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;M is reducible&lt;/strong&gt; with $\displaystyle \lim_{k \to \infty} M^k$ existing.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;M is reducible&lt;/strong&gt; with $\displaystyle \lim_{k \to \infty} M^k$ not existing.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let $\large P$ be the transition probability matrix for an &lt;strong&gt;irreducible Markov chain&lt;/strong&gt; on states ${S_1, S_2, \dots, S_n}$, and let $\large \pi^T$ be the left-hand Perron vector for $\large P$ (i.e., $\large \pi^T P = \pi^T$, $|\pi|_1 = 1$).&lt;/p&gt;

&lt;p&gt;The following hold for every initial distribution $p^T(0)$:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The $k^{th}$ step transition matrix is $P^k$.&lt;br /&gt;
The $\large (i,j)$-entry in $P^k$ is the probability of moving from $S_i$ to $S_j$ in exactly $k$ steps.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The $k$th step distribution vector is given by&lt;br /&gt;
\(\large
p^T(k) = p^T(0) P^k\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If $P$ is &lt;strong&gt;primitive&lt;/strong&gt; (aperiodic), and if $\large e$ is the column vector of all 1’s, then&lt;br /&gt;
\(\large
\lim_{k \to \infty} P^k = e \pi^T
\quad \text{and} \quad
\lim_{k \to \infty} p^T(k) = \pi^T\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If $P$ is &lt;strong&gt;imprimitive&lt;/strong&gt; (periodic), then&lt;br /&gt;
\(\large
\lim_{k \to \infty} \frac{I + P + \cdots + P^{k-1}}{k} = e \pi^T\)&lt;br /&gt;
and&lt;br /&gt;
\(\large
\lim_{k \to \infty} \frac{p^T(0) + p^T(1) + \cdots + p^T(k-1)}{k} = \pi^T\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Regardless of whether $P$ is primitive or imprimitive, the $j^{th}$ component $\pi_j$ of $\pi^T$ represents the &lt;strong&gt;long-run fraction of time&lt;/strong&gt; that the chain is in $S_j$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The vector $\pi^T$ is the &lt;strong&gt;unique stationary distribution vector&lt;/strong&gt; for the chain, because it is the unique probability distribution satisfying&lt;/p&gt;

\[\large
\pi^T P = \pi^T\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So we have seen that &lt;strong&gt;a unique positive PageRank vector&lt;/strong&gt; exists when the Google matrix is stochastic and irreducible. Further, with the additional property of aperiodicity, the power method will converge to this PageRank vector, regardless of the starting vector for the iterative process.&lt;/p&gt;

&lt;h3 id=&quot;implementation&quot;&gt;Implementation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Problems to handle:&lt;/strong&gt;
If there are:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;pages with dead ends (have no out-links)&lt;/li&gt;
  &lt;li&gt;Spider traps (all out-links are within the group)
Our random walk could fail.
The solution for spider traps is teleport, at each time step, the random surfer has two options:&lt;/li&gt;
  &lt;li&gt;with probability $\beta$, follows a link at random&lt;/li&gt;
  &lt;li&gt;with probability $1-\beta$, jump to a random page&lt;/li&gt;
  &lt;li&gt;Common value for $\beta$ are 0.8 to 0.9&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For dead ends, the solution is teleport with probability $\large 1$.
The spider traps are not a mathematical problem, simply the result is not what we want.
On the contrary, &lt;strong&gt;Dead-ends are a mathematical problems&lt;/strong&gt; since our matrix wouldn’t be anymore a column stochastic matrix.&lt;/p&gt;

&lt;p&gt;This allows us to the final matrix, also called the &lt;strong&gt;google matrix&lt;/strong&gt;, it has the shape of:&lt;/p&gt;

\[G_{ij} =
\begin{cases}
\beta \dfrac{A_{ij}}{\sum\limits_{i} A_{ij}} + (1-\beta)\dfrac{1}{N}, &amp;amp; \text{if } \sum\limits_{i} A_{ij} \neq 0, \\[1.2em]
\dfrac{1}{N}, &amp;amp; \text{otherwise.}
\end{cases}
\quad \text{with } \beta = 0.85\]

&lt;p&gt;Where in this case $\large \dfrac{A_{ij}}{\sum\limits_{i} A_{ij}}$ is just the stochastic matrix $\large M$.
Here we don’t simulate the random walk, we think of it of being run infinitely long, computing this is equal to solve this recurvie equation by computing the leading eigevector of G.&lt;/p&gt;

&lt;p&gt;So random walk is just an intuition that we never truly simulate.&lt;/p&gt;

&lt;h2 id=&quot;example&quot;&gt;Example:&lt;/h2&gt;

&lt;p&gt;Take this graph, the goal will be to extract the feature that better represent the importance of each node in the over all graph.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/assets/PageRank-media/matrix-1.png&quot; class=&quot;wikilink&quot; alt=&quot;./resources/tensor.svg&quot; /&gt;
&lt;figcaption aria-hidden=&quot;true&quot;&gt;first graph&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The first step through the process is to represent the graph as an adjacency matrix:&lt;/p&gt;

&lt;p&gt;The matrix is going to be a $\large 6 \times 6$ matrix.
We set $\large A_{i,j} = 1$ if page $\large j$ has a link to page $\large i$ and $\large A_{i,j} = 0$ otherwise.&lt;/p&gt;

\[\large

A =
\begin{bmatrix}
0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\[4pt]  % from 1
1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\[4pt]  % from 2
0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 \\[4pt]  % from 3
0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\[4pt]  % from 4
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\[4pt]  % from 5
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0     % from 6
\end{bmatrix}\]

&lt;p&gt;Note that the $\large 1$ in the diagonal happen only if there is a self loop.&lt;/p&gt;

&lt;p&gt;Next we are going to assume that every link in that column are equally likely (equal probability out-links), so we divide every single entry of a column by the number of $\large 1$ in that column.
Since the columns must summ up to 1.&lt;/p&gt;

\[\large
M =
\begin{bmatrix}
0 &amp;amp; 1/2 &amp;amp; 1/2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\[4pt]  
1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1/3 &amp;amp; 0 \\[4pt]  
0 &amp;amp; 0 &amp;amp; 1/2 &amp;amp; 1 &amp;amp; 1/3 &amp;amp; 0 \\[4pt] 
0 &amp;amp; 1/2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\[4pt]  
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\[4pt]  
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1/3 &amp;amp; 0   
\end{bmatrix}\]

&lt;p&gt;Now we need to eliminate spider-traps and dead-ends.&lt;/p&gt;

&lt;p&gt;Do have this result we have to use the definition of google matrix I provided before:&lt;/p&gt;

\[G_{ij} =
\begin{cases}
\beta \dfrac{A_{ij}}{\sum\limits_{i} A_{ij}} + (1-\beta)\dfrac{1}{N}, &amp;amp; \text{if } \sum\limits_{i} A_{ij} \neq 0, \\[1.2em]
\dfrac{1}{N}, &amp;amp; \text{otherwise.}
\end{cases}
\quad \text{with } \beta = 0.85\]

\[\large
G =
0.85 \cdot
\begin{bmatrix}
0 &amp;amp; 1/2 &amp;amp; 1/2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\[4pt]  % from 1
1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1/3 &amp;amp; 0 \\[4pt]  % from 2
0 &amp;amp; 0 &amp;amp; 1/2 &amp;amp; 1 &amp;amp; 1/3 &amp;amp; 0 \\[4pt]  % from 3
0 &amp;amp; 1/2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\[4pt]  % from 4
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\[4pt]  % from 5
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1/3 &amp;amp; 0     % from 6
\end{bmatrix} 
+ 0.15 \cdot
\begin{bmatrix}
1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 \\[4pt]
1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 \\[4pt]
1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 \\[4pt]
1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 \\[4pt]
1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 \\[4pt]
1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6 &amp;amp; 1/6
\end{bmatrix}\]

&lt;p&gt;The middle step for computing this summation of matrixes is this:&lt;/p&gt;

\[G =
\begin{bmatrix}
0 &amp;amp; 17/40 &amp;amp; 17/40 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\[4pt]  % from 1
17/20 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 17/60 &amp;amp; 0 \\[4pt]  % from 2
0 &amp;amp; 0 &amp;amp; 17/40 &amp;amp; 17/20 &amp;amp; 17/60 &amp;amp; 0 \\[4pt]  % from 3
0 &amp;amp; 17/40 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\[4pt]  % from 4
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 17/20 \\[4pt]  % from 5
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 17/60 &amp;amp; 0     % from 6
\end{bmatrix} 
+
\begin{bmatrix}
1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 \\[4pt]
1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 \\[4pt]
1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 \\[4pt]
1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 \\[4pt]
1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 \\[4pt]
1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 \\[4pt]
\end{bmatrix}\]

&lt;p&gt;As the final result, you can see how the property of stochastic matrix remained, but we have a full matrix that avoid problems like spider-traps and dead-ends.&lt;/p&gt;

\[G =
\begin{bmatrix}
1/40 &amp;amp; 18/40 &amp;amp; 18/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 \\[4pt]
35/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 37/120 &amp;amp; 1/40 \\[4pt]
1/40 &amp;amp; 1/40 &amp;amp; 18/40 &amp;amp; 35/40 &amp;amp; 37/120 &amp;amp; 1/40 \\[4pt]
1/40 &amp;amp; 18/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 \\[4pt]
1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 35/40 \\[4pt]
1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 1/40 &amp;amp; 37/120 &amp;amp; 1/40 \\[4pt]
\end{bmatrix}\]

&lt;p&gt;Now we can iterate until we find a stable state:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Initialize $\large r^0 = [\frac{1}{N}, \dots, \frac{1}{N}]^T$&lt;/li&gt;
  &lt;li&gt;Iterate: $\large r^{t+1} = M \cdot r^t$&lt;/li&gt;
  &lt;li&gt;Stop when $\large \lvert r^{t+1} - r^t \rvert &amp;lt; \epsilon$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After few iteration (according to the epsilon you chose), you will arrive in a stable solution that in my case is:&lt;/p&gt;

\[\large
r = 
\begin{bmatrix}
0.24534 \\ 
0.25136 \\
0.26819 \\ 
0.13147 \\
0.06128 \\
0.04236
\end{bmatrix}

\;
\begin{array}{l}
\text{Node 1} \\ 
\text{Node 2} \\
\text{Node 3} \\
\text{Node 4} \\
\text{Node 5} \\
\text{Node 6}
\end{array}\]

&lt;p&gt;You can try this for yourself just executing the pythong code you will find below.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fractions&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;35&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;120&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;35&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;120&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;35&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;37&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;120&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Initial rank vector (uniform)
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Stopping threshold epsilon
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Fraction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;multiply_matrix_vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Multiply matrix M by column vector vec (both using Fraction)&quot;&quot;&quot;&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;vector_diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Max absolute difference between two vectors&quot;&quot;&quot;&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; 

&lt;span class=&quot;c1&quot;&gt;# Iterative multiplication until convergence
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;iteration&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_next&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiply_matrix_vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector_diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iteration&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Iteration &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iteration&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r_next&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  | diff = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_next&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;r_final&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Converged PageRank:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r_final&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Node &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This vector represents the importance of the nodes in the graph.
A representative image of the importance of nodes in the graph is provided below.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/assets/PageRank-media/matrix (2)-1.png&quot; class=&quot;wikilink&quot; alt=&quot;./resources/tensor.svg&quot; /&gt;
&lt;figcaption aria-hidden=&quot;true&quot;&gt;final graph&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Although node 5 receives links from nodes 2 and 3, its PageRank is relatively small. This is because PageRank distributes a node’s “importance” proportionally across all of its outgoing links. Node 2 and node 3 each link to multiple nodes, so the portion of their rank that reaches node 5 is only a fraction of their total importance. In other words, PageRank measures the &lt;strong&gt;probability that a random surfer lands on a node&lt;/strong&gt;, taking into account both the importance of linking nodes and how their rank is split among their outgoing links. Therefore, even if a node is linked by important nodes, it may still have a low rank if those nodes distribute their rank widely.&lt;/p&gt;

&lt;h2 id=&quot;references-&quot;&gt;References 📚&lt;/h2&gt;

&lt;h3 id=&quot;research-papers&quot;&gt;Research Papers&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Jure Leskovec et al., &lt;em&gt;Pixie: System for Large-Scale Graph Mining&lt;/em&gt;, &lt;a href=&quot;https://cs.stanford.edu/people/jure/pubs/pixie-www18.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Bindel, &lt;em&gt;Lecture Notes CS6210&lt;/em&gt;, Cornell University, &lt;a href=&quot;https://www.cs.cornell.edu/~bindel/class/cs6210-f16/lec/2016-10-17.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Vesak, &lt;em&gt;Stochastic Processes Notes&lt;/em&gt;, &lt;a href=&quot;https://vesak90.userpage.fu-berlin.de/stochastic.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;books&quot;&gt;Books&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Horn, R.A. &amp;amp; Johnson, C.R., &lt;em&gt;Matrix Analysis&lt;/em&gt;, 2nd Edition, &lt;a href=&quot;https://www.anandinstitute.org/pdf/Roger_A.Horn.%20_Matrix_Analysis_2nd_edition(BookSee.org).pdf&quot;&gt;PDF&lt;/a&gt;, p. 549&lt;/li&gt;
  &lt;li&gt;Langville &amp;amp; Meyer, &lt;em&gt;Google’s PageRank and Beyond&lt;/em&gt;, &lt;a href=&quot;https://gi.cebitec.uni-bielefeld.de/_media/teaching/2019winter/alggr/langville_meyer_2006.pdf&quot;&gt;PDF&lt;/a&gt;, p. 186&lt;/li&gt;
  &lt;li&gt;Horn &amp;amp; Johnson, &lt;em&gt;Matrix Analysis&lt;/em&gt;, Chapter 8, &lt;a href=&quot;https://web.archive.org/web/20100307021652/http://www.matrixanalysis.com/Chapter8.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;markov-chains--linear-algebra&quot;&gt;Markov Chains &amp;amp; Linear Algebra&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Knill, &lt;em&gt;Lecture Notes on Markov Chains&lt;/em&gt;, Harvard University, &lt;a href=&quot;https://people.math.harvard.edu/~knill/teaching/math19b_2011/handouts/lecture33.pdf&quot;&gt;Lecture 33&lt;/a&gt;, &lt;a href=&quot;https://people.math.harvard.edu/~knill/teaching/math19b_2011/handouts/lecture34.pdf&quot;&gt;Lecture 34&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Knill, &lt;em&gt;Linear Algebra Probability Summary&lt;/em&gt;, &lt;a href=&quot;https://people.math.harvard.edu/~knill/teaching/math19b_2011/handouts/lecture36.pdf&quot;&gt;Lecture 36&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;MathOverflow, &lt;em&gt;Examples on Non-Diagonalizable Stochastic Matrices&lt;/em&gt;, &lt;a href=&quot;https://mathoverflow.net/questions/51887/non-diagonalizable-doubly-stochastic-matrices&quot;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;exercises&quot;&gt;Exercises&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Knight, &lt;em&gt;Markov Chains Exercise Sheet with Solutions&lt;/em&gt;, &lt;a href=&quot;https://vknight.org/OR_Methods/Markov_Chains/Markov_Chains_Exercise_Sheet-Solutions.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Probability Course, &lt;em&gt;Solved Problems&lt;/em&gt;, &lt;a href=&quot;https://www.probabilitycourse.com/chapter11/11_2_7_solved_probs.php&quot;&gt;Link&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Gordon, &lt;em&gt;Solved Problems on Markov Chains&lt;/em&gt;, &lt;a href=&quot;https://web.ma.utexas.edu/users/gordanz/notes/solved_problems.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reference-notes&quot;&gt;Reference Notes&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Fewster, &lt;em&gt;Transition Matrix Definitions&lt;/em&gt;, &lt;a href=&quot;https://www.stat.auckland.ac.nz/~fewster/325/notes/ch8.pdf&quot;&gt;PDF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Stanford EE363, &lt;em&gt;Perron-Frobenius Theory&lt;/em&gt;, &lt;a href=&quot;https://stanford.edu/class/ee363/lectures/pf.pdf?utm_source=chatgpt.com&quot;&gt;PDF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;YouTube, &lt;em&gt;Perron-Frobenius Theory Lecture&lt;/em&gt;, &lt;a href=&quot;https://www.youtube.com/watch?v=TU0ankRcHmo&amp;amp;t=1298s&quot;&gt;Watch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Simone Piccinini</name><email>piccinini.simone2005@gmail.com</email></author><category term="blog" /><category term="jekyll" /><category term="images" /><summary type="html">The pipeline for training a Graph Neural Network can be schematized as follows: Input graph → Structural features → Learning algorithm → Prediction One of the most challenging aspects of this pipeline is the design of structural features. These features aim to capture the essential patterns and relationships within the graph. Automating this process is a key goal in graph machine learning, and it is commonly referred to as feature engineering.</summary></entry><entry><title type="html">Backpropagation</title><link href="http://localhost:4000/blog/2025/08/02/backpropagation.html" rel="alternate" type="text/html" title="Backpropagation" /><published>2025-08-02T00:00:00+02:00</published><updated>2025-08-02T00:00:00+02:00</updated><id>http://localhost:4000/blog/2025/08/02/backpropagation</id><content type="html" xml:base="http://localhost:4000/blog/2025/08/02/backpropagation.html">&lt;p&gt;The backpropagation is main algorithm used for training neural network via gradient descend.
To understand deeply the topics in this essay require a basic knowledge of calculus and linear algebra.&lt;/p&gt;

&lt;p&gt;What does it mean training a network so that it could learn and generalize to solve our problem?
Training a network means adjusting his weight and biases according on how the model perform better for our current problem.
To achieve this result we aim to reduce the function of loss.
This is what gradient descend stands for.
Finding the local minimum of our function of loss to minimize the error.
So the gradient descend is just a routine of optimization of our model.&lt;/p&gt;

&lt;p&gt;Backpropagation can make training a network with gradient descend as much as ten million times faster, relative to a naive implementation.&lt;/p&gt;

&lt;p&gt;Backpropagation is mainly used for training neural networks by efficiently computing gradients needed for optimization. However, its underlying principle of reverse-mode automatic differentiation has found applications in other fields such as scientific computing, control theory, computer graphics, and engineering design. In these areas, backpropagation helps optimize complex systems by enabling fast and accurate calculation of sensitivities and parameter gradients.&lt;/p&gt;

&lt;p&gt;In this essay I’m going to use sources like the excellent free book on neural network written by Micheal Nilsen, you will find all the resources at the end of the essay.&lt;/p&gt;

&lt;h2 id=&quot;computational-graph&quot;&gt;Computational graph&lt;/h2&gt;

&lt;p&gt;Computational graphs are very useful in computer science, they allow you to track and compute complex mathematical expressions by breaking them down into a sequence of simple operations. Each node in a computational graph represents an operation (like addition, multiplication, or a more complex function), and each edge carries data, often in the form of tensors or scalars.&lt;/p&gt;

&lt;p&gt;For example consider the expression:
\(e = (a+b) * (b+1)\)&lt;/p&gt;

&lt;p&gt;We can add a intermediate step:
\(c = a+b\) and \(d = b+1\).
And get the result \(e = c * d\).
&lt;img src=&quot;/assets/Backpropagation-media/95d9ad30fd5932138b603f7a38133d73835120aa.svg&quot; class=&quot;wikilink&quot; alt=&quot;./resources/cg_1.svg&quot; style=&quot;width: 100%; max-width: 600px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To evaluate the expression we can set the input variable to certain values, for example a=2, b=1.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/Backpropagation-media/0b4c50deb00024de16f8bf39938eef77600c9d48.svg&quot; class=&quot;wikilink&quot; alt=&quot;./resources/cg_2.svg&quot; style=&quot;width: 100%; max-width: 600px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To know how \(e\) varies changes \(a\) or \(b\) we have to compute partial derivatives in the computational graph.
For evaluating this graph we need the sum rule and the product rule.&lt;/p&gt;

\[\frac{\partial }{\partial a}(a+b) = \frac{\partial a}{\partial a} + \frac{\partial b}{\partial a} = 1\]

\[\frac{\partial }{\partial u}(uv) = \frac{\partial u}{\partial u}\cdot v+\frac{\partial v}{\partial u}\cdot u\]

&lt;p&gt;&lt;img src=&quot;/assets/Backpropagation-media/0d06683576b3c735410bd8341dc24b0da52ca10b.svg&quot; class=&quot;wikilink&quot; alt=&quot;./resources/cg_3.svg&quot; style=&quot;width: 100%; max-width: 600px;&quot; /&gt;
The key idea to understand the efficiency of backpropagation and follow the next part of the essay is to grasp the difference between &lt;strong&gt;forward mode differentiation&lt;/strong&gt; and &lt;strong&gt;backward mode differentiation&lt;/strong&gt;.
&lt;strong&gt;Forward-mode differentiation&lt;/strong&gt; starts at an input to the graph and moves towards the end. At every node, it sums all the paths feeding in. Each of those paths represents one way in which the input affects that node. By &lt;strong&gt;adding them up&lt;/strong&gt;, we get the total way in which the node is affected by the input, it’s derivative.
&lt;strong&gt;Reverse-mode differentiation&lt;/strong&gt;, on the other hand, starts at an output of the graph and moves towards the beginning. At each node, &lt;strong&gt;it merges all paths&lt;/strong&gt; which originated at that node.&lt;/p&gt;

&lt;p&gt;Let’s take for example we have a function of three variable:&lt;/p&gt;

\[f(x,y,z) = z\]

&lt;p&gt;The total differential for a function of three variable is:&lt;/p&gt;

\[df = \frac{\partial f}{\partial x}dx + \frac{\partial f}{\partial y}dy+\frac{\partial f}{\partial z}\]

&lt;p&gt;If in turn x,y,z depends on a variable t, we can apply the &lt;strong&gt;chain rule&lt;/strong&gt; and the total differential becomes:&lt;/p&gt;

\[\frac{\partial f}{\partial t} = \frac{\partial f}{\partial x}\cdot\frac{\partial x}{\partial t} + \frac{\partial f}{\partial y}\cdot\frac{\partial y}{\partial t}+\frac{\partial f}{\partial z}\cdot\frac{\partial z}{\partial t}\]

&lt;p&gt;To understand how \(a\) changes according to nodes that are not directly connected to it we just applying the chain rule.
Let’s analyze how \(e\) changes if \(a\) changes:&lt;/p&gt;

\[\frac{\partial e}{\partial a} = \frac{\partial e}{\partial c}\cdot \frac{\partial c}{\partial a} = 2\cdot 1=2\]

&lt;p&gt;Let’s analyze how \(e\) changes if \(b\) changes, in this case &lt;strong&gt;we have to sum the contribution for multiple paths.&lt;/strong&gt;&lt;/p&gt;

\[\frac{\partial e}{\partial b} = \frac{\partial e}{\partial c}\cdot \frac{\partial c}{\partial b} + \frac{\partial e}{\partial d}\cdot \frac{\partial d}{\partial b}  = 2 \cdot 1 + 3 \cdot 1 = 5\]

&lt;p&gt;Now let’s make a concrete example using the previous expression.&lt;br /&gt;
Understanding this will help you appreciate &lt;strong&gt;why backpropagation is so efficient&lt;/strong&gt; when training neural networks.&lt;/p&gt;

&lt;p&gt;To see how the output \(e\) changes when the input $b$ changes, we could use a &lt;strong&gt;forward-mode differentiation&lt;/strong&gt; approach:&lt;br /&gt;
We would start from the node where \(b=1\) and &lt;strong&gt;follow all paths forward&lt;/strong&gt; through the graph, &lt;strong&gt;summing the contributions&lt;/strong&gt; that lead to \(e\).&lt;/p&gt;

&lt;p&gt;However, we would have to repeat this process separately for &lt;strong&gt;each input&lt;/strong&gt; (like a, b, etc.) — which can be slow when there are many inputs, as in neural networks.&lt;/p&gt;

&lt;figure&gt;

&lt;img src=&quot;/assets/Backpropagation-media/8bfdf7f5612baeb02bbcea9a31d0a465c334cf53.svg&quot; alt=&quot;Description&quot; style=&quot;width: 100%; max-width: 600px;&quot; /&gt;
&lt;figcaption&gt;

Figure 1: Feedforward differentiation starting from the node b.
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;With this approach we would have to do the same thing for the \(a\) node, and then sum up the contributions of all the derivatives of all the input nodes.&lt;/p&gt;

&lt;p&gt;Using a &lt;strong&gt;backward differentiation&lt;/strong&gt; approach (reverse-mode), we start from the final output and propagate gradients &lt;strong&gt;backward&lt;/strong&gt; through the graph.&lt;br /&gt;
This allows us to compute the &lt;strong&gt;partial derivatives of the output with respect to all input variables in a single backward pass&lt;/strong&gt;, thanks to &lt;strong&gt;factoring and reusing common paths&lt;/strong&gt; via the chain rule.&lt;/p&gt;
&lt;figure&gt;

&lt;img src=&quot;/assets/Backpropagation-media/1b13aa38787f99388b86100a809639240e9fd24a.svg&quot; alt=&quot;Description&quot; style=&quot;width: 100%; max-width: 600px;&quot; /&gt;
&lt;figcaption&gt;

Figure 2: Backward differentiation starting from the node e we are able to get the derivatives of all the input nodes.
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;p&gt;This example show how if we have a function with multiple inputs and few outputs a function like:
\(\large
f:\mathbb{R}^n\to \mathbb{R}\)&lt;/p&gt;

&lt;p&gt;Is &lt;strong&gt;much more efficient&lt;/strong&gt; using backward differentiation to understand how the output changes of the input changes.
If for example we have 1,000,000 inputs, forward differentiation would require 1,000,000 passes through the network, while backpropagation differentiation would require just 2 passes through the network (&lt;strong&gt;one for evaluating the expression at each node and one for calculating the derivatives&lt;/strong&gt;).
So &lt;strong&gt;reverse-mode is ~500,000× faster&lt;/strong&gt; in practice for this case!&lt;/p&gt;

&lt;h2 id=&quot;structure-of-a-neural-network-and-notation&quot;&gt;Structure of a neural network and notation&lt;/h2&gt;

&lt;p&gt;This is a simple schema of a neural network, it’s composed of one layer of input, one hidden layer and one output layer.
&lt;img src=&quot;/assets/Backpropagation-media/simplenet.svg&quot; class=&quot;wikilink&quot; alt=&quot;simplenet.svg&quot; style=&quot;width: 100%; max-width: 600px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;notation&quot;&gt;notation&lt;/h3&gt;

&lt;p&gt;Simple photo that follows show the notation on neurons connected between each other.
Two neurons are connected by a weight, the value of a neuron is given by \(a_{j}^l\) where l represents the current layer while \(j\) stands for which neuron in the layer we are referring to.
Each neuron has a bias (\(b_{t}^l\)), the meaning of the notation if the same as the previous.&lt;/p&gt;

&lt;figure style=&quot;text-align: center; margin: 1em auto;&quot;&gt;
  &lt;img src=&quot;/assets/Backpropagation-media/notation.svg&quot; alt=&quot;notation.svg&quot; style=&quot;width: 100%; max-width: 600px;&quot; /&gt;
  &lt;figcaption&gt;notation.svg&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In a neural network each neuron is connected with all the other neurons in the next layer, and the strength of each connection is characterized by a &lt;strong&gt;weight&lt;/strong&gt;. In addition to these weighted connections, each neuron also has a &lt;strong&gt;bias&lt;/strong&gt; term, which acts like an adjustable constant input that allows the neuron to shift its activation function, helping the network better fit the data by enabling the output to be offset independently of the inputs. The neuron computes a weighted sum of its inputs, adds the bias, and then passes the result through an &lt;strong&gt;activation function&lt;/strong&gt; — a nonlinear transformation such as ReLU, sigmoid, or tanh. This nonlinearity is crucial, as it allows the network to learn and approximate complex, non-linear mappings between inputs and outputs. Without activation functions, no matter how many layers the network has, it would behave like a linear model.&lt;/p&gt;

&lt;p&gt;This photos shows the steps to evaluate the level of activation of one neuron, \(z_{j}^1\) is an intermediate step, while \(a_{j}^1\) is the final level of activation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/Backpropagation-media/activation.svg&quot; class=&quot;wikilink&quot; alt=&quot;activation.svg&quot; style=&quot;width: 100%; max-width: 600px; &quot; /&gt;&lt;/p&gt;

&lt;p&gt;Each neuron of the \(\ell\) layer takes as input the activation level of all the other neurons in the \(\ell-1\)  layer of the network.
We can calculate the activation of the neuron \(j\) in the layer \(\ell\) as:&lt;/p&gt;

\[\large
a_{j}^{\ell} = \sigma \left(\sum_{k} w_{jk}^{\ell} a_{k}^{\ell -1} + b_{j}^{\ell}\right) 

\tag{1}\]

&lt;p&gt;I will be much easier to manage if we would translate this in vector form, it’s simple to show that the last expression is equal to:&lt;/p&gt;

\[\large
a^{\ell}=\sigma\left( W^{\ell}a^{\ell-1} + b^{\ell} \right)\]

&lt;p&gt;And our intermediate step will be:&lt;/p&gt;

\[\large z^{\ell} = W^{\ell}a^{\ell-1} + b^{\ell}\]

&lt;h2 id=&quot;cost-function&quot;&gt;Cost function&lt;/h2&gt;

&lt;p&gt;When training a neural network, we begin by defining a &lt;strong&gt;loss function&lt;/strong&gt; \(l(h(x),y)\) that quantifies how far the model’s prediction \(h(x)\) is from the true output \(y\) for a &lt;strong&gt;single data point&lt;/strong&gt;. This single-point loss is exactly what we use to compute gradients via &lt;strong&gt;backpropagation&lt;/strong&gt;, updating the model’s weights to reduce the error. However, in practice, we don’t just have one example — we are given a dataset of samples \({(X_{1},Y_{2}),…,(X_{n},Yn)}\), which are drawn from some &lt;strong&gt;unknown distribution&lt;/strong&gt; \(P(x,y)\). Our goal would ideally be to minimize the &lt;strong&gt;expected loss&lt;/strong&gt; over this distribution:&lt;/p&gt;

\[\large
\mathbb{E}_{(x,y) \sim P} \left[ \ell(h(x), y) \right] = \int \ell(h(x),y) dP(x,y)\]

&lt;p&gt;But since $P(x,y)$ is unknown, we cannot compute this expectation directly. Instead, we approximate it using the &lt;strong&gt;empirical average&lt;/strong&gt; over our dataset:&lt;/p&gt;

\[\large
\hat{C} = \frac{1}{n} \sum_{x} \ell(h(X_{i}),Y_{i})

\tag{2}\]

&lt;p&gt;This empirical loss is what we minimize in practice. And since it’s a sum of differentiable single-sample losses, we can still apply &lt;strong&gt;backpropagation&lt;/strong&gt;, either over the entire sum (in batch gradient descent) or over small subsets (in stochastic or mini-batch gradient descent). Thus, the justification for using backpropagation over many samples stems from the fact that the empirical loss is an &lt;strong&gt;estimator of the expected loss&lt;/strong&gt; — and the best tool we have for reducing it with gradient-based methods.&lt;/p&gt;

&lt;p&gt;This cost function takes as input &lt;strong&gt;all the weights and biases&lt;/strong&gt; of the network and measures &lt;strong&gt;how far off the network’s predictions are&lt;/strong&gt; compared to the actual target outputs.&lt;/p&gt;

&lt;p&gt;The choice on which cost function to choose varies according to the problem we are trying to solve.
For this essay I’m going to take in consideration the simplest cost function that is the &lt;strong&gt;Mean squared error&lt;/strong&gt;:&lt;/p&gt;

\[\large
C(w,b)=\frac{1}{n}\sum_{x} ||y(x)− a^L(x)||^2

\tag{3}\]

&lt;p&gt;Where \(y(x)\) is the desired output, \(a\) is the output we can, it obviously depends on the weights and biases of the network, while \(x\) stands for the training samples.&lt;/p&gt;

&lt;p&gt;Indeed the cost for a simple training example is:&lt;/p&gt;

\[\large
C_{x} = \frac{1}{2} ||y-a^L||^2

\tag{4}\]

&lt;p&gt;What backpropagation allow us to do is to calculate \(\large \frac{\partial C_{X}}{\partial w}\) and \(\large \frac{\partial C_{x}}{\partial b}\) and then finding \(\large \frac{\partial C}{\partial w}\) and \(\large \frac{\partial C}{\partial b}\) averaging over the training samples.&lt;/p&gt;

&lt;p&gt;I said earlier that the cost function take as input all the weight and biases of the network, I need to precise better that.
The cost function take as input &lt;strong&gt;the last layer of the network&lt;/strong&gt;, or also called the &lt;strong&gt;“prediction&lt;/strong&gt;” of the network, the prediction depends on all the weights and biases of the network.
The cost function measures &lt;strong&gt;how close or far is the prediction compared to the actual result&lt;/strong&gt;, backpropagation through gradient descend, is an algorithm to make this prediction closes as possible.
&lt;img src=&quot;/assets/Backpropagation-media/cf_1.svg&quot; class=&quot;wikilink&quot; alt=&quot;cf_1.svg&quot; style=&quot;width: 100%; max-width: 600px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;backpropagation-derivation&quot;&gt;Backpropagation derivation&lt;/h2&gt;

&lt;p&gt;Once understood the problem we are trying to solve, let’s try to address the problem in a more mathematical way.
The heart of backpropagation is understand how the cost function varies, if the matrix of weights of the first layer varies.
Or in a mathematical way:&lt;/p&gt;

\[\large
\frac{\partial C \left( a^L\left( a^{L-1}\right) \dots\left( a^l\left(w^l \right)\right)\right)}{\partial w^l}\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;\(C\) is a &lt;strong&gt;scalar loss function&lt;/strong&gt; (like MSE or cross-entropy)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;\(w^l \in \mathbb{R}^{n\times m}\) is the &lt;strong&gt;weight matrix&lt;/strong&gt; for layer \(l\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The output \(C\) depends on the activations, which depend on the weights from &lt;strong&gt;all previous layers&lt;/strong&gt;, including \(w^l\)&lt;/p&gt;
    &lt;h5 id=&quot;what-we-want-to-do-is-to-apply-the-chain-rule-layer-by-layer-through-the-computational-graph&quot;&gt;What we want to do is to apply the chain rule layer by layer through the computational graph.&lt;/h5&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We have a scalar function \(C\) that depends on a vector \(a^L\) &lt;strong&gt;that depends on a vector that depends on a vector&lt;/strong&gt;…. so on until we have a vector that depends on a matrix \(w^l\).&lt;/p&gt;

&lt;p&gt;Since the cost \(C\) is a scalar, and the weights \(w^l\) are a matrix, we’re computing the &lt;strong&gt;derivative of a scalar function with respect to a matrix&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;But this scalar depends on a composition of many functions — vectors and matrices interacting across layers. So to compute this derivative, we’ll need to use:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Derivative of a scalar with respect to vector (gradient)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Derivative of a scalar with respect to matrix&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Derivative of a vector with respect to a vector (Jacobian)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Chain rule for matrix calculus&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;derivative-of-a-scalar-function-with-respect-to-a-vector&quot;&gt;Derivative of a scalar function with respect to a vector&lt;/h3&gt;

&lt;p&gt;Let \(C:\mathbb{R}^n\to \mathbb{R}\), with \(v=(x_1,x_{2},\dots,x_{n})\).&lt;/p&gt;

\[\frac{\partial C}{\partial v} = \nabla C =\begin{pmatrix}
\frac{\partial C}{\partial x_{1}} \\
\frac{\partial C}{\partial x_{2}} \\
\vdots \\
\frac{\partial C}{\partial x_{n}}
\end{pmatrix}\]

&lt;p&gt;Example: suppose \(v=a^L\) , \(C=C(a^L)\), then:&lt;/p&gt;

\[\frac{\partial C}{\partial a^L} = \begin{pmatrix}
\frac{\partial C}{\partial a_{1}^L} \\
\frac{\partial C}{\partial a_{2}^L} \\
\vdots \\
\frac{\partial C}{\partial a_{n}^L}
\end{pmatrix}\]

&lt;p&gt;So: 
\(\large \frac{\partial C}{\partial a^L} = \nabla_{a_{L}} C\in \mathbb{R}^{n\times1}\)&lt;/p&gt;

&lt;p&gt;The derivative of a scalar function with respect to a vector is just the gradient of that function, &lt;strong&gt;this tells us how much the cost changes when each component of the vector \(a^L\) changes&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;vector-function-of-a-vector-variable&quot;&gt;Vector function of a vector variable&lt;/h3&gt;

&lt;p&gt;Let \(f:\mathbb{R}^n\to \mathbb{R}^m\),\(x=(x_{1},x_{2}\dots,x_{n})\), then:&lt;/p&gt;

\[f(x) = \begin{pmatrix}
f_{1}(x) \\
f_{2}(x) \\
\vdots \\
f_{m}(x)


\end{pmatrix}\]

&lt;p&gt;Each \(f_{i}\) is a scalar function of the same vector \(x \in \mathbb{R}^n\).
Then the derivative is the &lt;strong&gt;Jacobian matrix&lt;/strong&gt;:&lt;/p&gt;

\[\frac{\partial f}{\partial x} = J=
\begin{pmatrix}
\frac{\partial f_1}{\partial x_1} &amp;amp; \cdots &amp;amp; \frac{\partial f_1}{\partial x_n} \\
\vdots &amp;amp; \ddots &amp;amp; \vdots \\
\frac{\partial f_m}{\partial x_1} &amp;amp; \cdots &amp;amp; \frac{\partial f_m}{\partial x_n}
\end{pmatrix}\]

&lt;p&gt;This generalizes the gradient it tells &lt;strong&gt;how each component of the output vector changes according to every input component&lt;/strong&gt;.
Each row is the gradient of one component function \(f_{i}(x)\). So the Jacobian is a stack of gradients.&lt;/p&gt;

&lt;h3 id=&quot;derivative-of-a-scalar-function-with-respect-to-a-matrix&quot;&gt;Derivative of a scalar function with respect to a matrix&lt;/h3&gt;

\[\large 
f:\mathbb{R}^{n \times m}\to \mathbb{R}\]

&lt;p&gt;So \(f\) is a scalar function of a matrix.
The derivative is defined as:&lt;/p&gt;

\[\frac{\partial f}{\partial W}
= \begin{pmatrix}
\frac{\partial f}{\partial w_{11}} &amp;amp; \cdots &amp;amp; \frac{\partial f}{\partial w_{1m}} \\
\vdots &amp;amp; \ddots &amp;amp; \vdots \\
\frac{\partial f}{\partial w_{n1}} &amp;amp; \cdots &amp;amp; \frac{\partial f}{\partial w_{nm}} \\
\end{pmatrix}
\in \mathbb{R}^{n \times m}\]

&lt;p&gt;We differentiate the scalar function with respect to each component of the matrix — and the result is again a matrix.&lt;/p&gt;

&lt;p&gt;Turning back to our final objective, that is to compute \(\large \frac{\partial C}{\partial w^l}\).
This falls under the case of a &lt;strong&gt;scalar function of a matrix&lt;/strong&gt;, and produces a matrix of partial derivatives.
However, to compute it via the chain rule, we often encounter intermediate expressions such as the derivative of a &lt;strong&gt;vector with respect to a matrix&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&quot;this-brings-us-to-study-vector-valued-functions-of-matrix-variables&quot;&gt;This brings us to study vector-valued functions of matrix variables:&lt;/h3&gt;

\[\large f:\mathbb{R}^{n\times m}\to \mathbb{R}^k\]

&lt;p&gt;This function takes as input a matrix and gives out a vector, so the function would look something like:&lt;/p&gt;

\[f(W)=\begin{pmatrix}
f_{1}(W) \\
f_{2}(W) \\
\vdots \\
f_{k}(W)
\end{pmatrix}\]

&lt;p&gt;What is \(\huge \frac{\partial C}{\partial W}\)?&lt;/p&gt;

&lt;p&gt;Each component function $f_{i}(W)$ is a scalar function of the matrix $W$. So we can take its derivative just like before:
\(\large 
\frac{\partial f_{i}}{\partial W}\in R^{n\times m}\)&lt;/p&gt;

&lt;p&gt;Now since we have $k$ of them we just stuck these matrixes the one after the other.
That gives us a cube-like object with shape:
\(\large 
\frac{\partial f}{\partial W} \in \mathbb{R}^{k \times n \times m}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This is a rank-3 tensor.&lt;/strong&gt;
This tensor tells us how each output component $f_{i}$ changes with each element $w_{jk}$​ of the input matrix.&lt;/p&gt;

&lt;p&gt;In our case the function $f$ corresponds to $a^l$, and the components of $a^l$ are the individual activations of $a_{i}^l$, which correspond to the different $f_{i}$ .&lt;/p&gt;

&lt;p&gt;This is an example of matrixes for the first 3 layers of the network: layer 1, layer 2 and layer 3.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/assets/Backpropagation-media/64b73722444b2241bacbd82e7e9349dce2b896f0.svg&quot; class=&quot;wikilink&quot; alt=&quot;./resources/tensor.svg&quot; /&gt;
&lt;figcaption aria-hidden=&quot;true&quot;&gt;./resources/tensor.svg&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;em&gt;Figure 2: In our case, the function $f$ corresponds to $a^l$, and the components of $a^l$ are the individual activations $a^l_i$, which correspond to the different $f_i$.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We understood how to differentiate with respect to vectors an matrixes, now we need to find the namesake of the chainrule but for vectors.
So we need to evaluate something like:&lt;/p&gt;

\[\large \frac{\partial C \left(y(x) \right)}{\partial x}\]

&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$C$ is a scalar function&lt;/li&gt;
  &lt;li&gt;$\large y:\mathbb{R}^n\to \mathbb{R}^m$ is a vector valued function&lt;/li&gt;
  &lt;li&gt;and $\large x \in \mathbb{R}^n$
The composition $C(y(x))$ is still a scalar function — it maps $\large x∈\mathbb{R}^n$ to a real number via $\large y$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As we saw before, we are taking the derivative of a scalar function with respect to a vector, and that is just the gradient.&lt;/p&gt;

\[\large \frac{\partial C \left(y(x) \right)}{\partial x} =\nabla_{c} C=\begin{pmatrix}
\frac{\partial C}{\partial x_{1}} \\
\frac{\partial C}{\partial x_{2}} \\
\vdots \\
\frac{\partial C}{\partial x_{n}}
\end{pmatrix}\]

&lt;p&gt;But now, we can go a step further and express how $\large C$ depends on $\large x$ &lt;strong&gt;through&lt;/strong&gt; $\large y(x)$.&lt;/p&gt;

\[\large C=C(y_{1}(x),y_{2}(x),\dots,y_{m}(x))\]

&lt;p&gt;So what we are dealing with is a composition of functions, so we use the chain rule for multivariable calculus we have seen when we were dealing with the computational graphs:&lt;/p&gt;

\[\large \frac{\partial C}{\partial x_{j}}=\sum_{i=1}^m \frac{\partial C}{\partial y_{i}} \cdot\frac{\partial y_{i}}{\partial x_{j}}\]

&lt;p&gt;This tells us: to compute how $C$ changes as we vary $\large x_{j}$​, we look at how each $\large y_{i}$​ changes with $x_{j}$​, weighted by how sensitive $\large C$ is to $\large y_{i}$​.&lt;/p&gt;

&lt;p&gt;$\large x$ is a vector of $\large n$ components, so if we stack all these pieces of chain rule together we get:&lt;/p&gt;

\[\large \nabla_{x} C=\begin{pmatrix}
\sum_{i=1}^m \frac{\partial C}{\partial y_{i}} \cdot\frac{\partial y_{i}}{\partial x_{1}} \\
\sum_{i=1}^m \frac{\partial C}{\partial y_{i}} \cdot\frac{\partial y_{i}}{\partial x_{2}} \\
\vdots \\
\sum_{i=1}^m \frac{\partial C}{\partial y_{i}} \cdot\frac{\partial y_{i}}{\partial x_{n}}
\end{pmatrix}\]

&lt;h4 id=&quot;matrix-form-vector-chain-rule&quot;&gt;Matrix Form: Vector Chain Rule&lt;/h4&gt;

&lt;p&gt;Rather than writing all those sums explicitly, we can express this &lt;strong&gt;compactly using matrix multiplication&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Let’s define:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;Jacobian matrix&lt;/strong&gt; $\large \frac{\partial y}{\partial x}\in \mathbb{R}^{m \times n}$ , whose $(i,j)-th$ entry is $\large \frac{\partial y_{i}}{\partial x_{j}}$&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;gradient of $\large C$ with respect to $\large y$&lt;/strong&gt;, $\large \nabla_{y} C =\mathbb{R}^m$, whose $i$ components is $\large \frac{\partial C}{\partial y_{i}}$
Then the full gradient is:&lt;/li&gt;
&lt;/ul&gt;

\[\large \nabla_{c} C = \left(\frac{\partial y}{\partial x}\right)^{\top} \cdot \nabla_{y} C

\tag{5}\]

&lt;p&gt;That is the Chain rule for vector-valued function.&lt;/p&gt;

&lt;h2 id=&quot;chain-rule-with-matrix-valued-variables&quot;&gt;Chain Rule with Matrix-Valued Variables&lt;/h2&gt;

&lt;p&gt;We now want to compute the derivative of a scalar function composed with a function of a matrix:&lt;/p&gt;

\[\large \frac{\partial C(Y(W))}{\partial W}\]

&lt;hr /&gt;

&lt;p&gt;Differentiate a scalar with respect to a matrix:
\(\large
\frac{\partial C}{\partial W} =
\begin{pmatrix}
\frac{\partial C}{\partial w_{11}} &amp;amp; \frac{\partial C}{\partial w_{12}} &amp;amp; \cdots &amp;amp; \frac{\partial C}{\partial w_{1n}} \\
\frac{\partial C}{\partial w_{21}} &amp;amp; \frac{\partial C}{\partial w_{22}} &amp;amp; \cdots &amp;amp; \frac{\partial C}{\partial w_{2n}} \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
\frac{\partial C}{\partial w_{m1}} &amp;amp; \frac{\partial C}{\partial w_{m2}} &amp;amp; \cdots &amp;amp; \frac{\partial C}{\partial w_{mn}} \\
\end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;Our case the scalar C depends on a vector $\large y$, and that vector depends on the matrix $\large W$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\large C: \mathbb{R}^{m} \to \mathbb{R}$ is a scalar function&lt;/li&gt;
  &lt;li&gt;$\large  y: \mathbb{R}^{k \times n} \to \mathbb{R}^{m}$ is a vector-valued function&lt;/li&gt;
  &lt;li&gt;$\large  W \in \mathbb{R}^{k \times n}$ is a matrix input&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;In our case the scalar function $\large C$ Depends on a vector $\large y$ and the vector depends on a matrix $\large W$.&lt;/p&gt;

&lt;p&gt;This leads us to the composition&lt;/p&gt;

\[\large  C\left(y\left(W\right)\right)\]

&lt;p&gt;With $\large y$ with the form of:&lt;/p&gt;

\[\large y=\begin{pmatrix}
y_{1}(W) \\
y_{2}(W) \\
\vdots \\
y_{k}(W)
\end{pmatrix}\]

&lt;p&gt;Now we have to use the matrix definition looking at the components of the matrix $\large W$:&lt;/p&gt;

\[\large \left[ \frac{\partial C\left(y(W)\right)}{\partial W}\right]_{jk} = \frac{\partial C\left(y(W)\right)}{\partial w_{jk}}\]

&lt;p&gt;How $\large C$ depends on $\large w_{ij}$? It depends on $\large y$ that depends on $\large W$. So let’s apply the chain rule but for scalars.&lt;/p&gt;

\[\large \frac{\partial C(y(W))}{\partial w_{jk}} = \sum_{i=1}^m \frac{\partial C}{\partial y_i} \cdot \frac{\partial y_i}{\partial w_{jk}}\]

&lt;p&gt;Now we can put it back into the full matrix:&lt;/p&gt;

\[\large \frac{\partial C(y(W))}{\partial W} =
\begin{pmatrix}
\sum_i \frac{\partial C}{\partial y_i} \cdot \frac{\partial y_i}{\partial w_{11}} &amp;amp; \cdots &amp;amp; \sum_i \frac{\partial C}{\partial y_i} \cdot \frac{\partial y_i}{\partial w_{1n}} \\
\sum_i \frac{\partial C}{\partial y_i} \cdot \frac{\partial y_i}{\partial w_{21}} &amp;amp; \cdots &amp;amp; \sum_i \frac{\partial C}{\partial y_i} \cdot \frac{\partial y_i}{\partial w_{2n}} \\
\vdots &amp;amp; \ddots &amp;amp; \vdots \\
\sum_i \frac{\partial C}{\partial y_i} \cdot \frac{\partial y_i}{\partial w_{m1}} &amp;amp; \cdots &amp;amp; \sum_i \frac{\partial C}{\partial y_i} \cdot \frac{\partial y_i}{\partial w_{mn}} \\
\end{pmatrix}\]

&lt;p&gt;Each entry in this matrix is a sum of scalar-by-scalar products. We just applied the scalar chain rule to each component and it’s all there in one matrix.&lt;/p&gt;

&lt;h4 id=&quot;lets-simplify-the-notation&quot;&gt;Let’s simplify the notation.&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;$\large \frac{\partial y}{\partial W}$ is a tensor because it’s a vector with respect to a matrix.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$\large \frac{\partial C}{\partial y}$ it’s a vector
So we can write what we wrote as:&lt;/p&gt;

\[\large \frac{\partial C(y(W))}{\partial W} = \sum_{i=1}^k \frac{\partial C}{\partial y_{i}} \cdot \frac{\partial y_{i}}{\partial W}\]

    &lt;h4 id=&quot;using-tensor-contraction&quot;&gt;Using Tensor contraction.&lt;/h4&gt;
    &lt;p&gt;To simplify again our notation to scale it better on our neural network we need to use a tensor contraction.
A &lt;strong&gt;tensor contraction&lt;/strong&gt; is an operation on a tensor that arises from the canonical pairing of a vector space and its dual.
When we “contract” over an axis, we’re summing along that dimension reducing its size.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So the final expression is:&lt;/p&gt;

\[\large \frac{\partial C}{\partial W} = \sum_{i=1}^k \frac{\partial C}{\partial y_{i}} \cdot \frac{\partial y_{i}}{\partial W} \to\large \frac{\partial C}{\partial W} =  \frac{\partial y}{\partial W} \overset{i}{\cdot} \frac{C}{\partial y}

\tag{6}\]

&lt;p&gt;That’s how we simplify the chain rule when the variable is a matrix and the intermediate function is vector-valued.&lt;/p&gt;

&lt;h1 id=&quot;backpropagation-algorithm&quot;&gt;Backpropagation algorithm&lt;/h1&gt;

&lt;p&gt;Our main goal is to compute:&lt;/p&gt;

\[\large \frac{\partial C \left( a^L\left( a^{L-1}\right) \dots\left( a^l\left(w^l \right)\right)\right)}{\partial w^l}

\tag{7}\]

&lt;p&gt;We are taking the derivative with respect to a matrix, but this scalar depends on a vector, that depends on a vector that depends on a vector and so on until it depends on the matrix $\large w^l$.&lt;/p&gt;

&lt;p&gt;We start from the outermost layer, the layer linked with the matrix $\large w^l$ and we compute the tensor contraction:&lt;/p&gt;

\[\large \frac{\partial C}{\partial W} =  \frac{\partial a^l}{\partial w^l} \overset{i}{\cdot} \frac{C}{\partial a^l}

\tag{8}\]

&lt;p&gt;But the vector $\large a^l$ depends on the vector $\large a^{l+1}$ and so on until the last layer $a^L$, to compute how each layer change each other we use the chain rule for vectors we found earlier:&lt;/p&gt;

\[\large \frac{\partial C}{\partial a^l} = \left(\frac{\partial a^{l+1}}{\partial a^l}\right)^{\top} \cdot \frac{\partial C}{\partial a^{l+1}} 

\tag{9}\]

&lt;p&gt;And this is true for every layer:&lt;/p&gt;

\[\large \frac{\partial C}{\partial a^{l+1}} = \left(\frac{\partial a^{l+2}}{\partial a^{l+1}}\right)^{\top} \cdot \frac{\partial C}{\partial a^{l+2}}\]

&lt;p&gt;And that is the recursive hear of backpropagation until the last layer $\large a^L$.&lt;/p&gt;

&lt;h3 id=&quot;error-backpropagation-signal&quot;&gt;Error backpropagation signal&lt;/h3&gt;

&lt;p&gt;Some sources define the error signal as:&lt;/p&gt;

\[\large
\delta^l := \frac{\partial C}{\partial a^l}\]

&lt;p&gt;This can be used recursively:&lt;/p&gt;

\[\large \frac{\partial C}{\partial a^l} = \left(\frac{\partial a^{l+1}}{\partial a^l}\right)^{\top} \cdot \frac{\partial C}{\partial a^{l+1}}  \to \delta^l= \left(\frac{\partial a^{l+1}}{\partial a^l}\right)^{\top} \cdot \delta^{l+1}\]

&lt;p&gt;However, in standard backpropagation, the error is usually defined as:
\(\large
\delta^l := \frac{\partial C}{\partial z^l}\)&lt;/p&gt;

&lt;p&gt;The reason for the last definition is the most straight forward:&lt;/p&gt;

&lt;p&gt;If we are for example in the neuron $\large j^{th}$ in the layer one. If we make a little change to the weighed input of the neuron $\large z_{j}^1$ adding the quantity $\large \Delta z_{j}^1$, then the activation input instead of outputting $\large \sigma(z_{j}^1)$ it will output $\large \sigma(z_{j}^1 + \Delta z_{j}^1 )$.
This change propagates through all the network and finally change the cost function of a quantity:&lt;/p&gt;

\[\frac{\partial C}{\partial z_{j}^1}\cdot\Delta z_{j}^1\]

&lt;p&gt;If we want to try to minimize the cost function, we can try to chose the quantity $\large \Delta z_{j}^1$ so that makes the cost smaller.
If the quantity $\large \frac{\partial C}{\partial z_{j}^1}$ is close to zero then there is little to change, indeed if the quantity $\large \frac{\partial C}{\partial z_{j}^1}$ is big we can chose the quantity $\large \Delta z_{j}^1$ of the opposite sign to try to minimize the cost.&lt;/p&gt;

&lt;p&gt;In this heuristic sense, this quantity $\large \frac{\partial C}{\partial z_{j}^1}$ is the measure of the error of the neuron $j^{th}$ in the layer 1.&lt;/p&gt;

\[\large \delta_{j}^1=\frac{\partial C}{\partial z_{j}^1}\]

&lt;h2 id=&quot;why-both-definitions-can-coexist&quot;&gt;Why both definitions can coexist&lt;/h2&gt;

&lt;p&gt;There is no contradiction between defining the error as $\large \frac{\partial C}{\partial a^l}$ or $\large \frac{\partial C}{\partial z^l}$, because they are directly related through the chain rule.
Since $\large a^l = \sigma(z^l)$, we apply the chain rule:&lt;/p&gt;

\[\large
\frac{\partial C}{\partial z^l} = \frac{\partial C}{\partial a^l} \cdot \frac{\partial a^l}{\partial z^l}\]

&lt;p&gt;Because $\large \sigma$ is applied elementwise, this becomes an elementwise (Hadamard) product:&lt;/p&gt;

\[\large
\frac{\partial C}{\partial z^l} = \frac{\partial C}{\partial a^l} \odot \sigma'(z^l)\]

&lt;p&gt;That is,&lt;/p&gt;

\[\large
\delta^l = \tilde{\delta}^l \odot \sigma'(z^l)\]

&lt;p&gt;where&lt;/p&gt;

\[\large
\tilde{\delta}^l := \frac{\partial C}{\partial a^l}\]

&lt;p&gt;So depending on the context, one may define and propagate $\large \tilde{\delta}^l$ (via the recursive expression), and then obtain the standard error $\large \delta^l$ by applying the derivative of the activation. They are just two steps in the same computation, not conflicting definitions.&lt;/p&gt;

&lt;p&gt;This is the key equation for backpropagation that links the error of one layer to the layer of the next one.&lt;/p&gt;

\[\Large \delta^l= \left(\frac{\partial a^{l+1}}{\partial a^l}\right)^{\top} \cdot \delta^{l+1}

\tag{11}\]

&lt;p&gt;Since we are interested in finding:&lt;/p&gt;

\[\large \frac{\partial C}{\partial w^l} \text{ for all layers  }l\]

&lt;p&gt;Once we know the vector $\large \delta^l$ we can compute the weight gradient using a tensor contraction (using equation 8).&lt;/p&gt;

\[\large 
\frac{\partial C}{\partial w^l} =  \frac{\partial a^l}{\partial w^l} \overset{i}{\cdot} \delta^l 
\tag{12}\]

&lt;p&gt;Before jumping to the algorithm itself and the implementation though code, I think is due to spend at least a little time explaining how the gradient descend work. How exactly finding all these derivative and stuff how actually is going to make our neural network learn something?&lt;/p&gt;

&lt;h2 id=&quot;gradient-descend&quot;&gt;Gradient descend&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;The gradient is a vector that points in the direction of the greatest rate of increase of a scalar field.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The gradient is calculable only of a scalar-valued differentiable function.&lt;/p&gt;

&lt;p&gt;So the gradient is defined only for functions that take a $n-dimention$ vector and gives as output a scalar.&lt;/p&gt;

\[\large
f:\mathbb{R}^n\to\mathbb{R}\]

&lt;p&gt;So you can use gradients only with scalar fields.&lt;/p&gt;

&lt;p&gt;We can define the gradient of a function $f(r)$ as:&lt;/p&gt;

\[\large df = \nabla f dr\]

&lt;p&gt;What is formula is saying is how much the function will change according to the displacement $dr$.
If we are in an 3D space then $dr = (dx,dy,dz)$.&lt;/p&gt;

&lt;p&gt;Since $\nabla f$ is a vector that point to the steepest increase of the function.&lt;/p&gt;

&lt;p&gt;If the displacement is towards the vector $\nabla f$ then df is going to be bigger, while if the displacement is in the opposite direction the change of the function is going to be little.
If the displacement is orthogonal to the $\nabla f$ vector, there is going to be no change in the the function, this is for the definition of dot product.&lt;/p&gt;

&lt;p&gt;The gradient for a scalar function at a point $p$ is defined as:&lt;/p&gt;

\[\large {\displaystyle \nabla f(p)={\begin{bmatrix}{\frac {\partial f}{\partial x_{1}}}(p)\\\vdots \\{\frac {\partial f}{\partial x_{n}}}(p)\end{bmatrix}}}

\tag{13}\]

&lt;p&gt;This definition works only if the function is differentiable in p, otherwise obviously we cannot do the partial derivates.&lt;/p&gt;

&lt;p&gt;By the definition of gradient follows that if we want to minimize our scalar function, that quantifies how far the model’s prediction $h(x)$ is from the true output $y$ for a &lt;strong&gt;single data point&lt;/strong&gt;, then we have to move in the opposite direction of the gradient from that point $\large p$.&lt;/p&gt;

&lt;p&gt;The update rule for the gradient descend is:&lt;/p&gt;

\[\large a_{n+1} = a_{n} - \eta\nabla f(a_{n})\]

&lt;p&gt;$\large \eta$ is the learning rate, is represent how long is the step you are going to take towards the function local minimum, $\Large a_{n}$ is the point you are evaluating the gradient, from that point you move to the direction of the fastest decrease of the function.&lt;/p&gt;

&lt;p&gt;How can we apply gradient descent to learn in a neural network? The idea is to use gradient descent to find the weights $\large w_{k}$ and biases $\large b_{l}$ which minimize the cost in Equation. To see how this works, let’s restate the gradient descent update rule, with the weights and biases replacing the variables $\large v_{j}$. In other words, our “position” now has components $\large w_{k}$ and $\large b_{l}$, and the gradient vector $\nabla C$ has corresponding components $\large \frac{\partial C}{\partial w_{k}}$ and $\large \frac{\partial C}{\partial b}$. Writing out the gradient descent update rule in terms of components, we have the update rule for the bias:
\(\large
 b_{1} \to b_{1}^{′} = b_{1} - \eta \frac{\partial C}{\partial b_{1}}
 \tag{14}\)&lt;/p&gt;

&lt;p&gt;And the update rule for the weights of every single layer:&lt;/p&gt;

\[\large w_{k} \to w_{k}^{′} = w_{k}-\eta \frac{\partial C}{\partial w_{k}}
\tag{15}\]

&lt;p&gt;By applying this rule we can “roll down the hill” and hopefully find a minimum of the cost function.
Of course we cannot be sure that the minimum we’ll find will be the global minimum of the function, but just a local minimum.
The lesson is that we cannot be sure if there is a better configuration of weights and biases that make our model predict better.&lt;/p&gt;

&lt;p&gt;A better implementation of gradient descend is stochastic gradient descend, as show in the chapter of the cost function, we have defined a cost function with multiple sample.
The idea of stochastic gradient descend is to estimate the gradient $\nabla C$ by computing  $\nabla C_{x}$ for a small sample of randomly chosen training inputs. By averaging over this small sample it turns out that we can quickly get a good estimate of the true gradient $\nabla C$, and this helps speed up gradient descent, and thus learning.&lt;/p&gt;

&lt;p&gt;We are calling those random input training samples $\large(X_{1},X_{2},\dots,X_{m} )$ we will call them &lt;strong&gt;mini-batch&lt;/strong&gt;.
The $m$ must be large enough to have a roughly similar result for the gradient.
So that $\nabla C_{X_{j}}$ and $\nabla C_{X}$ will be almost the same, but the gradient will be much easier to compute.&lt;/p&gt;

&lt;p&gt;If this is true so we have:&lt;/p&gt;

\[\Large 

\frac{\sum_{j=1}^m \nabla C_{X_{j}}}{m} \approx \frac{\sum_{X} \nabla C_{X}}{n} =\nabla_{} C\]

&lt;p&gt;Where the second sum is over &lt;strong&gt;all&lt;/strong&gt; the set of training data, so we get the approximation used for stochastic gradient descend:&lt;/p&gt;

\[\Large
\frac{\sum_{j=1}^m \nabla C_{X_{j}}}{m} \approx \nabla C\]

&lt;p&gt;Taking this into account the update rule for stochastic descend becomes:&lt;/p&gt;

\[\large
w_k' = w_k - \frac{\eta}{m} \sum_j \frac{\partial C_{X_j}}{\partial w_k}

\tag{16}\]

\[\large

b_l' = b_l - \frac{\eta}{m} \sum_j \frac{\partial C_{X_j}}{\partial b_l}
\tag{17}\]

&lt;p&gt;Let’s make a concrete example on how a neural network is trainer using stochastic gradient descend:&lt;/p&gt;

&lt;h3 id=&quot;start-of-training&quot;&gt;Start of Training:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Your model begins with &lt;strong&gt;random weights and biases&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;It doesn’t know anything yet — its predictions are probably &lt;strong&gt;garbage&lt;/strong&gt;.
    &lt;h3 id=&quot;epoch-1&quot;&gt;Epoch 1:&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Shuffle&lt;/strong&gt; the full training set (e.g. 100,000 examples).&lt;/li&gt;
  &lt;li&gt;Break it into &lt;strong&gt;mini-batches&lt;/strong&gt; (e.g. 100,000 examples → 1,562 mini-batches of 64 examples).
    &lt;h4 id=&quot;for-each-mini-batch&quot;&gt;For each mini-batch:&lt;/h4&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Backpropagation step&lt;/strong&gt;: compute the &lt;strong&gt;gradients&lt;/strong&gt; $\large \to$ how much each weight and bias should change to reduce the error.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Update&lt;/strong&gt; the weights and biases using the SGD formulas:
    &lt;h3 id=&quot;epoch-2&quot;&gt;Epoch 2:&lt;/h3&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Shuffle&lt;/strong&gt; the data again (important to avoid fixed patterns).&lt;/li&gt;
  &lt;li&gt;Repeat the mini-batch training process.&lt;/li&gt;
  &lt;li&gt;Now, weights and biases are &lt;strong&gt;slightly better&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;The model should start making &lt;strong&gt;better predictions&lt;/strong&gt;.
    &lt;h3 id=&quot;repeat-for-many-epochs-eg-10-50-100&quot;&gt;Repeat for Many Epochs (e.g., 10, 50, 100):&lt;/h3&gt;
  &lt;/li&gt;
  &lt;li&gt;With each epoch, the model sees &lt;strong&gt;all training examples again&lt;/strong&gt; (in new order).&lt;/li&gt;
  &lt;li&gt;Parameters are &lt;strong&gt;updated gradually&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;cost function&lt;/strong&gt; ( C ) (overall error) should &lt;strong&gt;decrease&lt;/strong&gt; over time.&lt;/li&gt;
  &lt;li&gt;The model becomes better at:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Generalizing&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Predicting accurately&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Learning&lt;/strong&gt; meaningful patterns&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;algorithm-and-implementation&quot;&gt;Algorithm and implementation&lt;/h2&gt;

&lt;p&gt;The algorithm for backpropagation is composed of three phases:
1) Input a sample of training example
2) For each training sample:
1) Feedforward phase
2) Compute output error
3) Backpropagate the error
3) Gradient descend&lt;/p&gt;

&lt;h3 id=&quot;2-phase&quot;&gt;2) phase&lt;/h3&gt;

&lt;p&gt;We need to find the quantities $\large \frac{\partial C}{\partial w^l}$ and $\large \frac{\partial C}{\partial b^l}$ for all layers $l$.&lt;/p&gt;

&lt;p&gt;So for each layer $l$ starting from the last one and moving backwards we have to compute first:&lt;/p&gt;

\[\large \delta^L :=\frac{\partial C}{\partial a^L}\]

&lt;p&gt;And then propagate the error backwards:&lt;/p&gt;

\[\large
\delta^l = \left( \frac{\partial a^{l+1}}{\partial a^l} \right)^\top \cdot \delta^{l+1}, \quad \text{for } l = L, L - 1, L - 2, \dots, 1

\tag{11}\]

&lt;p&gt;And for each layer compute what we are looking for as:&lt;/p&gt;

\[\large \frac{\partial C}{\partial w^l} =  \frac{\partial a^l}{\partial w^l} \overset{i}{\cdot} \delta^l 
\tag{12}\]

&lt;p&gt;And:&lt;/p&gt;

\[\large 
\frac{\partial C}{\partial b^l} = \delta^l\]

&lt;h3 id=&quot;3-phase&quot;&gt;3) phase&lt;/h3&gt;
&lt;p&gt;Once computed these derivatives we have to use gradient descend as:&lt;/p&gt;

\[\large
w_k' = w_k - \frac{\eta}{m} \sum_j \frac{\partial C_{X_j}}{\partial w_k}

\tag{16}\]

\[\large
b_l' = b_l - \frac{\eta}{m} \sum_j \frac{\partial C_{X_j}}{\partial b_l}
\tag{17}\]

&lt;p&gt;This is the big summary of the backpropagation algorithm of his most general form, if we want to implement this algorithm we need to decide which activation function and cost function we are going to use.
We are going to use the sigmoid function:&lt;/p&gt;

\[\large \sigma(x)=\frac{1}{1+e^{-x}},\quad \text{with} \quad \sigma^{′}(x)=\sigma(x)(1-\sigma(x))\]

&lt;p&gt;Meanwhile as cost function the squared error:&lt;/p&gt;

\[\large
C = \frac{1}{2} \| a^L - y \|^2,\]

&lt;p&gt;I’m going to use the code of Micheal Nielsen you can find on his book, however you can find the complete code on my github page used with training samples and MINST dataset.&lt;/p&gt;

&lt;p&gt;Before write the code we need to understand how the equations seen on phase 2 of the algorithm changes if we use the sigmoid function and the squared error as cost function.&lt;/p&gt;

&lt;p&gt;We start computing $\large \delta^L$ the error for the last layer we defined as:&lt;/p&gt;

\[\large \delta^L :=\frac{\partial C}{\partial a^L}\]

&lt;p&gt;Now if we take the derivative of the squared error with respect to $\large a^L$ we obtain (check for yourself):&lt;/p&gt;

\[\large 
\frac{\partial C}{\partial a^L}=a^L-y\]

&lt;p&gt;the error term at the output layer is defined as
\(\large
\delta^L = \frac{\partial C}{\partial z^L}.\)&lt;/p&gt;

&lt;p&gt;There is no contradiction in defining the output layer error as&lt;/p&gt;

\[\large
\delta^L := \frac{\partial C}{\partial a^L},\]

&lt;p&gt;because this is a valid partial derivative that describes how the cost changes with respect to the activation at layer $\large L$. However, during backpropagation, we ultimately need the derivative with respect to $\large z^L$, since $\large z^L$depends directly on the weights. By applying the chain rule, we refine our expression:&lt;/p&gt;

\[\large
\delta^L = \frac{\partial C}{\partial z^L} = \frac{\partial C}{\partial a^L} \odot \frac{\partial a^L}{\partial z^L}.\]

&lt;p&gt;Since we now that $\large \frac{\partial C}{\partial a^L} = a^L - y$, and we know the form of the derivative of the activation function:&lt;/p&gt;

\[\large
\frac{\partial a^L}{\partial z^L} = \sigma'(z^L) = a^L \odot (1 - a^L),\]

&lt;p&gt;this leads us to the final expression for the error on the last layer.&lt;/p&gt;

\[\large
\delta^L = (a^L - y) \odot a^L \odot (1 - a^L).\]

&lt;p&gt;Now we need to propagate the error back recursively using the rule:&lt;/p&gt;

\[\large
\delta^l = \left( \frac{\partial a^{l+1}}{\partial a^l} \right)^\top \cdot \delta^{l+1}, \quad \text{for } l = L, L - 1, L - 2, \dots, 1

\tag{11}\]

&lt;p&gt;&lt;strong&gt;What form does this take with the sigmoid activation function?&lt;/strong&gt;&lt;/p&gt;

\[\large
\begin{align*}
a^{l+1} &amp;amp;= \sigma(z^{l+1}) \\
        &amp;amp;= \sigma(W^{l+1} a^l + b^{l+1}) \\
\\
\frac{\partial a^{l+1}}{\partial a^l} 
        &amp;amp;= \frac{\partial \sigma(z^{l+1})}{\partial a^l} \\
        &amp;amp;= \frac{\partial \sigma(z^{l+1})}{\partial z^{l+1}} \cdot \frac{\partial z^{l+1}}{\partial a^l}
\end{align*}\]

&lt;p&gt;In the last term I’ve just applied the chain rule.
We know:&lt;/p&gt;

\[\large
z^{l+1} = W^{l+1} a^l + b^{l+1}\]

&lt;p&gt;Since this is a linear function of $\large a^l$, taking it’s derivative the second term of the last expression becomes:&lt;/p&gt;

\[\large
\frac{\partial z^{l+1}}{\partial a^l} = W^{l+1}\]

&lt;p&gt;Activations are applied element by element:&lt;/p&gt;

\[\large
a^{l+1} = \sigma(z^{l+1})\]

&lt;p&gt;So the derivative is a &lt;strong&gt;diagonal matrix&lt;/strong&gt; with the derivative of $\large \sigma$ applied to each entry:&lt;/p&gt;

\[\large
\frac{\partial \sigma(z^{l+1})}{\partial z^{l+1}} = \mathrm{diag}(\sigma'(z^{l+1}))\]

&lt;p&gt;This matrix has $\large \sigma’(z_i)$ on the diagonal and zeros elsewhere.
So adding all up together, the transpose becomes:&lt;/p&gt;

\[\large
\left( \frac{\partial a^{l+1}}{\partial a^l} \right)^\top = \left(\mathrm{diag}(\sigma'(z^{l+1})) \cdot (W^{l+1})^\top \right)\]

&lt;p&gt;We have not finished yet, we have to multiply this by the error of $\large \delta^{l+1}=\frac{\partial C}{\partial a^{l+1}}$.
But multiplying a diagonal matrix by a vector is just an elementwise product!&lt;/p&gt;

\[\large
\sigma'(z^{l+1}) \odot \left( (W^{l+1})^\top \cdot \frac{\partial C}{\partial a^{l+1}} \right)\]

&lt;p&gt;This gives us the clean recursive formula we love in backpropagation. So:&lt;/p&gt;

\[\large
\delta^l = (W^{l+1})^\top \cdot \delta^{l+1} \odot \sigma'(z^l)\]

&lt;p&gt;That we can write also (remembering for form of the first derivative of the activation function):&lt;/p&gt;

\[\large
\delta^l = (W^{l+1})^\top \cdot \delta^{l+1} \odot a^l \odot (1 - a^l)\]

&lt;h3 id=&quot;gradient-of-the-weights&quot;&gt;Gradient of the weights&lt;/h3&gt;

&lt;p&gt;Once we have the error vector $\large \delta^l$, we can compute the gradient of the cost with respect to the weights:&lt;/p&gt;

\[\large
\frac{\partial C}{\partial w^l} = \frac{\partial a^l}{\partial w^l} \overset{i}{\cdot} \delta^l\]

&lt;p&gt;Let’s examine a single element of this expression:&lt;/p&gt;

\[\large
\frac{\partial a^l_i}{\partial w^l_{jk}} = \frac{\partial \sigma(z^l_i)}{\partial w^l_{jk}} = \sigma'(z^l_i) \cdot \frac{\partial z^l_i}{\partial w^l_{jk}}\]

&lt;p&gt;Since:&lt;/p&gt;

\[\large
z^l_i = \sum_k w^l_{ik} a^{l-1}_k + b^l_i\]

&lt;p&gt;Then:&lt;/p&gt;

\[\large
\frac{\partial z^l_i}{\partial w^l_{jk}} =
\begin{cases}
a^{l-1}_k &amp;amp; \text{if } i = j \\
0 &amp;amp; \text{otherwise}
\end{cases}\]

&lt;p&gt;So:&lt;/p&gt;

\[\large
\frac{\partial a^l_j}{\partial w^l_{jk}} = \sigma'(z^l_j) \cdot a^{l-1}_k\]

&lt;p&gt;Multiplying by the error:&lt;/p&gt;

\[\large
\frac{\partial C}{\partial w^l_{jk}} = \delta^l_j \cdot a^{l-1}_k\]

&lt;p&gt;Switching to matrix form the full gradient is given by:&lt;/p&gt;

\[\large
\frac{\partial C}{\partial w^l} = \delta^l (a^{l-1})^\top\]

&lt;p&gt;This is the outer product between the error vector at layer $\large l$ and the activations from the previous layer.&lt;/p&gt;

&lt;h3 id=&quot;what-about-the-bias-large-bl&quot;&gt;What about the bias $\large b^l$?&lt;/h3&gt;

&lt;p&gt;The bias appears in the pre-activation like this:&lt;/p&gt;

\[\large
z^l = W^l a^{l-1} + b^l\]

&lt;p&gt;So when we differentiate with respect to $\large b^l$, it’s even simpler.&lt;/p&gt;

&lt;p&gt;We know:&lt;/p&gt;

\[\large
a^l = \sigma(z^l) = \sigma(W^l a^{l-1} + b^l)\]

&lt;p&gt;This means the bias $\large b^l$ directly and linearly affects the pre-activation $\large z^l$.&lt;br /&gt;
That is:&lt;/p&gt;

\[\large
\frac{\partial z^l}{\partial b^l} = I\]

&lt;p&gt;(the identity matrix).&lt;/p&gt;

&lt;p&gt;So, using the chain rule:&lt;/p&gt;

\[\large
\frac{\partial C}{\partial b^l} =
\frac{\partial z^l}{\partial b^l} \cdot \frac{\partial C}{\partial z^l}
= I \cdot \delta^l = \delta^l\]

&lt;p&gt;The gradient of the cost with respect to the bias is simply the error vector:&lt;/p&gt;

\[\large
\frac{\partial C}{\partial b^l} = \delta^l\]

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;h2 id=&quot;key-takeaway-from-general-backpropagation-to-implementation&quot;&gt;Key Takeaway: From General Backpropagation to Implementation&lt;/h2&gt;

&lt;p&gt;Starting from the most general backpropagation equations, we derived the specific forms used in practice, depending on the activation and cost functions chosen. Here is a concise summary of how the expressions evolve:&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;output-layer-error&quot;&gt;Output Layer Error&lt;/h3&gt;

\[\large
\delta^L := \frac{\partial C}{\partial a^L} \quad \to \quad \delta^L = (a^L - y) \odot a^L \odot (1 - a^L)\]

&lt;hr /&gt;

&lt;h3 id=&quot;recursive-error-for-hidden-layers&quot;&gt;Recursive Error for Hidden Layers&lt;/h3&gt;

\[\large
\delta^l = \left( \frac{\partial a^{l+1}}{\partial a^l} \right)^\top \cdot \delta^{l+1} \quad \to \quad \delta^l = (W^{l+1})^\top \cdot \delta^{l+1} \odot a^l \odot (1 - a^l)\]

&lt;hr /&gt;

&lt;h3 id=&quot;gradient-of-weights&quot;&gt;Gradient of Weights&lt;/h3&gt;

\[\large
\frac{\partial C}{\partial w^l} = \frac{\partial a^l}{\partial w^l} \overset{i}{\cdot} \delta^l \quad \to \quad \frac{\partial C}{\partial w^l} = \delta^l (a^{l-1})^\top\]

&lt;hr /&gt;

&lt;h3 id=&quot;gradient-of-biases&quot;&gt;Gradient of Biases&lt;/h3&gt;

\[\large
\frac{\partial C}{\partial b^l} = \delta^l\]

&lt;hr /&gt;

&lt;p&gt;This summary highlights the transition from theoretical derivatives to practical formulas used in neural network training.&lt;/p&gt;

&lt;h1 id=&quot;implementation&quot;&gt;Implementation&lt;/h1&gt;

&lt;p&gt;Now we can finally dive into the implementation of these algorithm using the equations found above, you can find the complete code on my github page, indeed below you will find a brief explanation of the key concepts.&lt;/p&gt;

&lt;h3 id=&quot;setup&quot;&gt;Setup&lt;/h3&gt;

&lt;p&gt;We are going to setup the data structures used in the class, the methods &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;np.random,randn(x,y)&lt;/code&gt; creates a structure of the shape indicated inside the parenthesis, created randomly.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;
&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]]&lt;/span&gt;
&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:])]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The zip function connect two turples, for example:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Simon&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Erik&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;22&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#the result would be
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Simon&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Erik&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;22&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For the biases we are creating a matrix of dimentions $\large y \times 1$, we are not assigning it a simple vector because with a matrix will be simpler doing later operation, like calculating the activation of a neuron.&lt;/p&gt;

&lt;p&gt;the code &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sizes[1:]&lt;/code&gt; is used to ignore the first layer (the input layer of the network), this is because we don’t want to assign biases this this layer.&lt;/p&gt;

&lt;p&gt;In the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;self.weights&lt;/code&gt; part of code we are randomly assigning the weights of the network, the code &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sizes[:-1], sizes[1:]&lt;/code&gt; is used to take into account all the layers excluding the first and the last one.
If for example our &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sizes&lt;/code&gt; turple is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[1,2,1]&lt;/code&gt; we would have two matrixes of dimentions: $\large 2 \times 1$ and $\large 1 \times 2$:&lt;/p&gt;

\[\large
\begin{pmatrix}
w_{1,1}^1 \\
w_{2,1}^1
\end{pmatrix} \text{ and }

\begin{pmatrix}
w_{1,1}^2 w_{1,2}^2
\end{pmatrix}\]

&lt;p&gt;(remember the notation for weights of a network I’ve introduced at the beginning of this article).&lt;/p&gt;

&lt;p&gt;This is just the introductory code, that set up in a random way the weights and biases of the network.&lt;/p&gt;

&lt;p&gt;Then we have the main function of this algorithm &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;update_mini_batch&lt;/code&gt;, is the function that update the weights and biases by applying gradient descend using backpropagation.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_mini_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

  

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;delta_nabla_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_nabla_w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dnb&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dnb&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_nabla_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dnw&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dnw&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_nabla_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nw&lt;/span&gt; 
                    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nw&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nb&lt;/span&gt;

                    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nb&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The first two line are used to set up a data structure where the gradient for the biases and weights are going to be calculated, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;np.zeros(b.shapes)&lt;/code&gt; creates a numpy array of zeros with the shape of b.&lt;/p&gt;

&lt;p&gt;The key part of this function is the loop, that for each value of the numpy array &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mini_batch&lt;/code&gt;, each item is composed of an input (x) and the expected output (y).&lt;/p&gt;

&lt;p&gt;The most important line of code is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta_nabla_b, delta_nabla_w = self.backprop(x, y)&lt;/code&gt; because it calls the function backpropagation that gives back for each layer $l$:&lt;/p&gt;

\[\delta\nabla b^l =\large \frac{\partial C}{\partial b^{l}}\]

&lt;p&gt;And&lt;/p&gt;

\[\delta\nabla w^l =\large \frac{\partial C}{\partial w^{l}}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dnb&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dnb&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_nabla_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dnw&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dnw&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_nabla_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Those two lines are used to &lt;strong&gt;accumulate the gradients&lt;/strong&gt; (partial derivatives) for each layer in a neural network during &lt;strong&gt;mini-batch stochastic gradient descent (SGD)&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Then we can update the weights and biases according to the equations we have previously analized:&lt;/p&gt;

\[\large
w_k' = w_k - \frac{\eta}{m} \sum_j \frac{\partial C_{X_j}}{\partial w_k}\]

\[\large
b_l' = b_l - \frac{\eta}{m} \sum_j \frac{\partial C_{X_j}}{\partial b_l}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nw&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nw&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nb&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nb&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally we are able to understand how this piece of code really work, and I’m going to explain in detail.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# feedforward
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# list to store all the activations, layer by layer
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;zs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# list to store all the z vectors, layer by layer
&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;zs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# backward pass
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost_derivative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid_prime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid_prime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sp&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;These first two lines as in the update_mini_batch function are used to set up the shape of the the numpy array that we are going to return at the end of the function.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The next piece of code is the feedforward phase, a key part of the process, we need to know the activation of every single layer if we want to backpropagate the error.
Remember from before how we defined the activation for a layer $\large \ell$.&lt;/p&gt;

\[\large a^{\ell}=\sigma\left( W^{\ell}a^{\ell-1} + b^{\ell} \right)\]

&lt;p&gt;The input x stores the activation of the &lt;strong&gt;first layer of the network&lt;/strong&gt; while the activation array is going to store all the activations arrays of the network.
Remember also how we defined the middle quantity $\large z$:&lt;/p&gt;

\[\large z^{\ell} = W^{\ell}a^{\ell-1} + b^{\ell}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# feedforward
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# list to store all the activations, layer by layer
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;zs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# list to store all the z vectors, layer by layer
&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;zs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Remembering that it’s easy to understand what this code is actually doing, is just applying the dot product between matrixes and adding the bias, and applying the activation function.&lt;/p&gt;

&lt;p&gt;Here comes the key part of the algorithm, how do we write the code for a backward pass?
First of all remember we need the compute the error of the last layer as:&lt;/p&gt;

\[\large
\delta^L = (a^L - y) \odot a^L \odot (1 - a^L)\]

&lt;p&gt;And we compute also the partial derivative for the weights and biases for the last layer.
\(\large
\frac{\partial C}{\partial w^L} = \delta^L (a^{L-1})^\top\)&lt;/p&gt;

\[\large
\frac{\partial C}{\partial b^L} = \delta^L\]

&lt;p&gt;Then we repeat this for all the layers until the first one, we compute the activation of the layer, calculate the error thank to the backpropagation equation:&lt;/p&gt;

\[\large
\delta^l = (W^{l+1})^\top \cdot \delta^{l+1} \odot a^l \odot (1 - a^l)\]

&lt;p&gt;And compute again the gradient of weights and biases, we’ll stop until we have reached the first layer and return the result.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# backward pass
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost_derivative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid_prime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid_prime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sp&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nabla_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nabla_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://neuralnetworksanddeeplearning.com/&quot;&gt;Neural Networks and Deep Learning – Michael Nielsen&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cs231n.github.io/optimization-2/&quot;&gt;CS231n: Convolutional Neural Networks for Visual Recognition&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.deeplearningbook.org/&quot;&gt;Deep Learning Book – Ian Goodfellow, Yoshua Bengio, Aaron Courville (MIT Press)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/data-science/backpropagation-step-by-step-derivation-99ac8fbdcc28&quot;&gt;Medium-Step-By-Step Derivation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Simone Piccinini</name><email>piccinini.simone2005@gmail.com</email></author><category term="blog" /><category term="jekyll" /><category term="images" /><summary type="html">The backpropagation is main algorithm used for training neural network via gradient descend. To understand deeply the topics in this essay require a basic knowledge of calculus and linear algebra.</summary></entry></feed>